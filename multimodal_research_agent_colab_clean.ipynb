{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDsCjUNYOoxZ",
    "outputId": "540c630b-46a4-4577-aa83-5d623e2f8aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.2/328.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cpu | torch = 2.9.0+cpu | numpy = 2.0.2\n",
      "WORKDIR = /content/research_agent\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "!pip -q install -U transformers accelerate sentence-transformers faiss-cpu pypdf pymupdf\n",
    "\n",
    "# Import standard utilities\n",
    "import os, re, json, math, textwrap, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# Import scientific stack\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Import PDF readers\n",
    "from pypdf import PdfReader\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Import vector search\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Import LLM runtime\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Set seeds to reduce randomness across runs\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Detect runtime device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"DEVICE = {DEVICE} | torch = {torch.__version__} | numpy = {np.__version__}\")\n",
    "\n",
    "# Configure torch behavior\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True if DEVICE == \"cuda\" else False\n",
    "\n",
    "# Define a workspace folder\n",
    "WORKDIR = \"/content/research_agent\"\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n",
    "print(\"WORKDIR =\", WORKDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwoTm66bXx69",
    "outputId": "db89b2fb-47e7-46b3-fb8c-d91fc7f7d39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved in: /content/research_agent\n",
      "FAILED      - who_school_based_violence_prevention_handbook.pdf | 0 MB |  | https://apps.who.int/iris/bitstream/handle/10665/324930/9789241515542-eng.pdf?sequence=1&isAllowed=y\n",
      "FAILED      - unicef_unesco_behind_the_numbers_school_violence_bullying.pdf | 0 MB |  | https://www.unicef.org/media/66496/file/Behind-the-Numbers.pdf | https://www.unicef.org/media/66496/file/Behind-the-Numbers.pdf?download=1\n",
      "FAILED      - unicef_cyberbullying_leaflet_en.pdf           | 0 MB |  | https://www.unicef.org/egypt/media/806/file/Cyberbullying-Leaflet-EN.pdf | https://www.unicef.org/egypt/media/806/file/Cyberbullying-Leaflet-EN.pdf?download=1\n",
      "OK          - kidpower_bullying_qa.pdf                      | 0.1 MB | d07d1d4cc4c8 | https://kidpowercs.org/wp-content/uploads/2017/09/Bullying-QA.pdf\n",
      "OK          - cci_anger_coping_strategies.pdf               | 0.14 MB | 7aebb13378f5 | https://www.cci.health.wa.gov.au/-/media/CCI/Mental-Health-Professionals/Interpersonal/Interpersonal---Information-Sheets/Interpersonal-Information-Sheet---02---Anger-Coping-Strategies.pdf\n",
      "OK          - cci_assert_yourself_module_01.pdf             | 0.18 MB | c14bdbec97d0 | https://www.cci.health.wa.gov.au/~/media/CCI/Consumer-Modules/Assert-Yourself/Assert-Yourself---01---What-is-Assertiveness.pdf\n",
      "OK          - cci_what_me_worry_overview_of_worry.pdf       | 0.3 MB | 7296b25c4e95 | https://www.cci.health.wa.gov.au/~/media/CCI/Consumer-Modules/What-Me-Worry/What-Me-Worry---02---Overview-of-Worry.pdf\n",
      "OK          - samhsa_anger_management_workbook.pdf          | 0.77 MB | 857dc745fe50 | https://library.samhsa.gov/sites/default/files/anger_management_workbook_508_compliant.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create work folder, define sources, retry downloads with browser headers, validate PDFs, write manifest\n",
    "import os, json, hashlib, subprocess\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "WORKDIR = Path(\"/content/research_agent\")\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "HEADERS = {\"User-Agent\": UA, \"Accept\": \"application/pdf,*/*;q=0.8\", \"Accept-Language\": \"en-US,en;q=0.9\", \"Referer\": \"https://www.google.com/\"}\n",
    "\n",
    "SOURCES = [\n",
    "  {\"name\":\"who_school_based_violence_prevention_handbook.pdf\",\n",
    "   \"urls\":[\"https://apps.who.int/iris/bitstream/handle/10665/324930/9789241515542-eng.pdf?sequence=1&isAllowed=y\"]},\n",
    "\n",
    "  {\"name\":\"unicef_unesco_behind_the_numbers_school_violence_bullying.pdf\",\n",
    "   \"urls\":[\"https://www.unicef.org/media/66496/file/Behind-the-Numbers.pdf\",\n",
    "           \"https://www.unicef.org/media/66496/file/Behind-the-Numbers.pdf?download=1\"]},\n",
    "\n",
    "  {\"name\":\"unicef_cyberbullying_leaflet_en.pdf\",\n",
    "   \"urls\":[\"https://www.unicef.org/egypt/media/806/file/Cyberbullying-Leaflet-EN.pdf\",\n",
    "           \"https://www.unicef.org/egypt/media/806/file/Cyberbullying-Leaflet-EN.pdf?download=1\"]},\n",
    "\n",
    "  {\"name\":\"kidpower_bullying_qa.pdf\",\n",
    "   \"urls\":[\"https://kidpowercs.org/wp-content/uploads/2017/09/Bullying-QA.pdf\"]},\n",
    "\n",
    "  {\"name\":\"cci_anger_coping_strategies.pdf\",\n",
    "   \"urls\":[\"https://www.cci.health.wa.gov.au/-/media/CCI/Mental-Health-Professionals/Interpersonal/Interpersonal---Information-Sheets/Interpersonal-Information-Sheet---02---Anger-Coping-Strategies.pdf\"]},\n",
    "\n",
    "  {\"name\":\"cci_assert_yourself_module_01.pdf\",\n",
    "   \"urls\":[\"https://www.cci.health.wa.gov.au/~/media/CCI/Consumer-Modules/Assert-Yourself/Assert-Yourself---01---What-is-Assertiveness.pdf\"]},\n",
    "\n",
    "  {\"name\":\"cci_what_me_worry_overview_of_worry.pdf\",\n",
    "   \"urls\":[\"https://www.cci.health.wa.gov.au/~/media/CCI/Consumer-Modules/What-Me-Worry/What-Me-Worry---02---Overview-of-Worry.pdf\"]},\n",
    "\n",
    "  {\"name\":\"samhsa_anger_management_workbook.pdf\",\n",
    "   \"urls\":[\"https://library.samhsa.gov/sites/default/files/anger_management_workbook_508_compliant.pdf\"]},\n",
    "]\n",
    "\n",
    "def sha1_12(p: Path) -> str:\n",
    "  h = hashlib.sha1()\n",
    "  with p.open(\"rb\") as f:\n",
    "    for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "      h.update(chunk)\n",
    "  return h.hexdigest()[:12]\n",
    "\n",
    "def looks_like_pdf(p: Path) -> bool:\n",
    "  if not p.exists() or p.stat().st_size < 10_000: return False\n",
    "  with p.open(\"rb\") as f: return f.read(4) == b\"%PDF\"\n",
    "\n",
    "def dl_requests(url: str, out: Path) -> bool:\n",
    "  try:\n",
    "    with requests.get(url, headers=HEADERS, stream=True, timeout=60) as r:\n",
    "      if r.status_code != 200: return False\n",
    "      out_tmp = out.with_suffix(out.suffix + \".part\")\n",
    "      with out_tmp.open(\"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024 * 256):\n",
    "          if chunk: f.write(chunk)\n",
    "      out_tmp.replace(out)\n",
    "    return looks_like_pdf(out)\n",
    "  except Exception:\n",
    "    return False\n",
    "\n",
    "def dl_curl(url: str, out: Path) -> bool:\n",
    "  cmd = f'curl -L -A \"{UA}\" -H \"Accept: application/pdf\" -o \"{out}\" \"{url}\"'\n",
    "  subprocess.run([\"bash\",\"-lc\", cmd], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "  return looks_like_pdf(out)\n",
    "\n",
    "manifest = []\n",
    "for src in SOURCES:\n",
    "  out = WORKDIR / src[\"name\"]\n",
    "  if looks_like_pdf(out):\n",
    "    manifest.append({\"name\":src[\"name\"], \"status\":\"OK (cached)\", \"size_mb\":round(out.stat().st_size/1024/1024,2), \"sha1_12\":sha1_12(out), \"url\":\"(cached)\"})\n",
    "    continue\n",
    "\n",
    "  ok_url, ok = None, False\n",
    "  for url in src[\"urls\"]:\n",
    "    if dl_requests(url, out) or dl_curl(url, out):\n",
    "      ok_url, ok = url, True\n",
    "      break\n",
    "\n",
    "  if ok:\n",
    "    manifest.append({\"name\":src[\"name\"], \"status\":\"OK\", \"size_mb\":round(out.stat().st_size/1024/1024,2), \"sha1_12\":sha1_12(out), \"url\":ok_url})\n",
    "  else:\n",
    "    if out.exists(): out.unlink()\n",
    "    manifest.append({\"name\":src[\"name\"], \"status\":\"FAILED\", \"size_mb\":0, \"sha1_12\":\"\", \"url\":\" | \".join(src[\"urls\"])})\n",
    "\n",
    "(WORKDIR / \"sources_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "print(f\"Files saved in: {WORKDIR}\")\n",
    "for m in manifest:\n",
    "  print(f\"{m['status']:<11} - {m['name']:<45} | {m['size_mb']} MB | {m['sha1_12']} | {m['url']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzSA9e9pZTVV",
    "outputId": "6aa79e0e-44e1-4708-bc84-134a37d73676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED - who_school_based_violence_prevention_handbook.pdf |  0.00 MB |              | \n",
      "FAILED - unicef_unesco_behind_the_numbers_school_violence_bullying.pdf |  0.00 MB |              | \n",
      "OK     - unicef_cyberbullying_leaflet_en.pdf           |  0.49 MB | 32fee49ee3c7 | https://www.sjcs.co.uk/sites/default/files/2024-04/Childnet%20Cyberbullying%20Leaflet.pdf\n",
      "\n",
      "Files saved in: /content/research_agent\n"
     ]
    }
   ],
   "source": [
    "# Set work directory\n",
    "import os, re, hashlib, subprocess, textwrap, requests\n",
    "WORKDIR = \"/content/research_agent\"\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n",
    "\n",
    "# Define browser-like headers\n",
    "UA = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "HDR = {\n",
    "  \"User-Agent\": UA,\n",
    "  \"Accept\": \"application/pdf,application/octet-stream;q=0.9,*/*;q=0.8\",\n",
    "  \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "  \"Referer\": \"https://www.unicef.org/\"\n",
    "}\n",
    "\n",
    "# Define helpers\n",
    "def sha1_12(p):\n",
    "  h = hashlib.sha1()\n",
    "  with open(p, \"rb\") as f:\n",
    "    for chunk in iter(lambda: f.read(1024*1024), b\"\"):\n",
    "      h.update(chunk)\n",
    "  return h.hexdigest()[:12]\n",
    "\n",
    "def looks_like_pdf(path, head_bytes=b\"\"):\n",
    "  if head_bytes:\n",
    "    return head_bytes.startswith(b\"%PDF\")\n",
    "  try:\n",
    "    with open(path, \"rb\") as f:\n",
    "      return f.read(4) == b\"%PDF\"\n",
    "  except:\n",
    "    return False\n",
    "\n",
    "def curl_fetch(url, out_path, referer=\"https://www.unicef.org/\"):\n",
    "  cmd = [\"bash\",\"-lc\", f'curl -L --fail -A \"{UA}\" -e \"{referer}\" \"{url}\" -o \"{out_path}\"']\n",
    "  r = subprocess.run(cmd, capture_output=True, text=True)\n",
    "  return r.returncode == 0\n",
    "\n",
    "def extract_pdf_urls_from_html(url):\n",
    "  try:\n",
    "    r = requests.get(url, headers=HDR, timeout=30)\n",
    "    html = r.text if r.ok else \"\"\n",
    "    found = re.findall(r'https?://[^\"\\']+?\\.pdf(?:\\?[^\"\\']*)?', html, flags=re.I)\n",
    "    return list(dict.fromkeys(found))\n",
    "  except:\n",
    "    return []\n",
    "\n",
    "def try_download(name, candidates):\n",
    "  out_path = os.path.join(WORKDIR, name)\n",
    "  for u in candidates:\n",
    "    try:\n",
    "      r = requests.get(u, headers=HDR, stream=True, allow_redirects=True, timeout=45)\n",
    "      if r.status_code == 200:\n",
    "        head = r.raw.read(8)\n",
    "        data = head + r.raw.read(1024*64)\n",
    "        if head.startswith(b\"%PDF\") or b\"%PDF\" in data[:4096]:\n",
    "          with open(out_path, \"wb\") as f:\n",
    "            f.write(head); f.write(r.raw.read())\n",
    "          if looks_like_pdf(out_path): return (\"OK\", u, out_path)\n",
    "        else:\n",
    "          tmp = out_path + \".tmp\"\n",
    "          with open(tmp, \"wb\") as f:\n",
    "            f.write(head); f.write(r.raw.read())\n",
    "          os.replace(tmp, out_path)\n",
    "          if looks_like_pdf(out_path): return (\"OK\", u, out_path)\n",
    "      if r.status_code in (401, 403, 429) or r.status_code >= 500:\n",
    "        if curl_fetch(u, out_path):\n",
    "          if looks_like_pdf(out_path): return (\"OK\", u, out_path)\n",
    "    except:\n",
    "      if curl_fetch(u, out_path):\n",
    "        if looks_like_pdf(out_path): return (\"OK\", u, out_path)\n",
    "  if os.path.exists(out_path):\n",
    "    try: os.remove(out_path)\n",
    "    except: pass\n",
    "  return (\"FAILED\", \"\", out_path)\n",
    "\n",
    "# Define failed targets with fallback URLs (use reputable alternates if a host blocks automated download)\n",
    "targets = [\n",
    "  (\"who_school_based_violence_prevention_handbook.pdf\", [\n",
    "    \"https://iris.who.int/bitstream/handle/10665/324930/9789241515542-eng.pdf?sequence=1\",\n",
    "    \"https://apps.who.int/iris/bitstream/handle/10665/324930/9789241515542-eng.pdf?sequence=1&isAllowed=y\",\n",
    "    \"https://www.unicef.org/media/58081/file/UNICEF-WHO-UNESCO-handbook-school-based-violence.pdf\",\n",
    "    \"https://resourcecentre.savethechildren.net/pdf/who_school_based_violence_prevention_1.pdf\",\n",
    "    \"https://dylbw5db8047o.cloudfront.net/uploads/who_school_based_violence_prevention_1.pdf\"\n",
    "  ]),\n",
    "  (\"unicef_unesco_behind_the_numbers_school_violence_bullying.pdf\", [\n",
    "    \"https://www.unicef.org/media/66496/file/Behind-the-Numbers.pdf?download=1\",\n",
    "    \"https://www.unicef.org/media/66496/file/Behind-the-Numbers.pdf\",\n",
    "    \"https://unesdoc.unesco.org/ark:/48223/pf0000366483/PDF/366483eng.pdf.multi\",\n",
    "    \"https://unesdoc.unesco.org/ark:/48223/pf0000366483/PDF/366483eng.pdf\"\n",
    "  ]),\n",
    "  (\"unicef_cyberbullying_leaflet_en.pdf\", [\n",
    "    \"https://www.unicef.org/egypt/media/806/file/Cyberbullying-Leaflet-EN.pdf?download=1\",\n",
    "    \"https://www.unicef.org/egypt/media/806/file/Cyberbullying-Leaflet-EN.pdf\",\n",
    "    \"https://www.sjcs.co.uk/sites/default/files/2024-04/Childnet%20Cyberbullying%20Leaflet.pdf\",\n",
    "    \"https://anti-bullyingalliance.org.uk/sites/default/files/uploads/attachments/hirescyberbullyingnobleed%281%29.pdf\"\n",
    "  ])\n",
    "]\n",
    "\n",
    "# Add discovered PDF links from wrapper pages (if any)\n",
    "for i,(name,cands) in enumerate(targets):\n",
    "  extra = []\n",
    "  for u in list(cands):\n",
    "    if u.endswith(\".pdf\") and \"resourcecentre.savethechildren.net/pdf/\" in u:\n",
    "      extra += extract_pdf_urls_from_html(u)\n",
    "  if extra:\n",
    "    targets[i] = (name, list(dict.fromkeys(extra + cands)))\n",
    "\n",
    "# Download and print manifest\n",
    "manifest = []\n",
    "for name, cands in targets:\n",
    "  status, used_url, path = try_download(name, cands)\n",
    "  size_mb = (os.path.getsize(path) / (1024*1024)) if (status==\"OK\" and os.path.exists(path)) else 0.0\n",
    "  s12 = sha1_12(path) if status==\"OK\" else \"\"\n",
    "  print(f\"{status:<6} - {name:<45} | {size_mb:>5.2f} MB | {s12:<12} | {used_url}\")\n",
    "  manifest.append((name, status, f\"{size_mb:.2f} MB\", s12, used_url))\n",
    "\n",
    "print(\"\\nFiles saved in:\", WORKDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYelNRWLad6t",
    "outputId": "e6309076-7555-42a2-9cdb-28558a48bc18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hERR 01/14  https://www.stopbullying.gov/bullying/what-is-bullying  -> 403 Client Error: Forbidden for url: https://www.stopbullying.gov/bullying/what-is-bullying\n",
      "ERR 02/14  https://www.stopbullying.gov/prevention/how-to-prevent-bullying  -> 403 Client Error: Forbidden for url: https://www.stopbullying.gov/prevention/how-to-prevent-bullying\n",
      "ERR 03/14  https://www.stopbullying.gov/kids/what-you-can-do  -> 403 Client Error: Forbidden for url: https://www.stopbullying.gov/kids/what-you-can-do\n",
      "ERR 04/14  https://www.stopbullying.gov/resources/what-you-can-do  -> 403 Client Error: Forbidden for url: https://www.stopbullying.gov/resources/what-you-can-do\n",
      "ERR 05/14  https://www.stopbullying.gov/resources/research-resources/mtss-prevention-approaches-and-effective-intervention  -> 403 Client Error: Forbidden for url: https://www.stopbullying.gov/resources/research-resources/mtss-prevention-approaches-and-effective-intervention\n",
      "ERR 06/14  https://www.stopbullying.gov/resources/get-help-now  -> 403 Client Error: Forbidden for url: https://www.stopbullying.gov/resources/get-help-now\n",
      "OK  07/14  www.cdc.gov  words=1078\n",
      "ERR 08/14  https://stacks.cdc.gov/view/cdc/21596  -> 403 Client Error: Forbidden for url: https://stacks.cdc.gov/view/cdc/21596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trafilatura.core:discarding data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK  09/14  www.apa.org  words=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trafilatura.core:discarding data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK  10/14  www.apa.org  words=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trafilatura.core:discarding data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK  11/14  www.apa.org  words=0\n",
      "OK  12/14  www.nhs.uk  words=928\n",
      "OK  13/14  www.nhsinform.scot  words=6754\n",
      "OK  14/14  selfhelp.cntw.nhs.uk  words=6326\n",
      "\n",
      "Saved: /content/research_agent/sources_web.jsonl\n",
      "OK: 7 | FAILED: 7\n"
     ]
    }
   ],
   "source": [
    "# Install HTML extraction utilities\n",
    "!pip -q install -U trafilatura beautifulsoup4 lxml\n",
    "\n",
    "# Define work paths\n",
    "import os, json, time, re, hashlib\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import requests\n",
    "import trafilatura\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WORKDIR = \"/content/research_agent\"\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n",
    "OUT_JSONL = os.path.join(WORKDIR, \"sources_web.jsonl\")\n",
    "\n",
    "# Define request headers\n",
    "UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "HEADERS = {\"User-Agent\": UA, \"Accept-Language\": \"en-US,en;q=0.9\"}\n",
    "\n",
    "# Define curated sources (bullying + anger/emotion regulation)\n",
    "URLS = [\n",
    "  \"https://www.stopbullying.gov/bullying/what-is-bullying\",\n",
    "  \"https://www.stopbullying.gov/prevention/how-to-prevent-bullying\",\n",
    "  \"https://www.stopbullying.gov/kids/what-you-can-do\",\n",
    "  \"https://www.stopbullying.gov/resources/what-you-can-do\",\n",
    "  \"https://www.stopbullying.gov/resources/research-resources/mtss-prevention-approaches-and-effective-intervention\",\n",
    "  \"https://www.stopbullying.gov/resources/get-help-now\",\n",
    "  \"https://www.cdc.gov/youth-violence/about/about-bullying.html\",\n",
    "  \"https://stacks.cdc.gov/view/cdc/21596\",\n",
    "  \"https://www.apa.org/topics/bullying\",\n",
    "  \"https://www.apa.org/topics/bullying/prevent\",\n",
    "  \"https://www.apa.org/ed/schools/primer/bullying\",\n",
    "  \"https://www.nhs.uk/mental-health/feelings-symptoms-behaviours/feelings-and-symptoms/anger/\",\n",
    "  \"https://www.nhsinform.scot/illnesses-and-conditions/mental-health/mental-health-self-help-guides/problems-with-anger-self-help-guide/\",\n",
    "  \"https://selfhelp.cntw.nhs.uk/self-help-guides/managing-anger/print/714\",\n",
    "]\n",
    "\n",
    "# Define text cleaning\n",
    "def clean_text(t: str) -> str:\n",
    "  t = re.sub(r\"\\r\", \"\\n\", t or \"\")\n",
    "  t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "  t = re.sub(r\"[ \\t]{2,}\", \" \", t)\n",
    "  return t.strip()\n",
    "\n",
    "# Define HTML download\n",
    "def fetch_html(url: str) -> str:\n",
    "  r = requests.get(url, headers=HEADERS, timeout=45, allow_redirects=True)\n",
    "  r.raise_for_status()\n",
    "  return r.text\n",
    "\n",
    "# Define main-text extraction with fallback\n",
    "def extract_main_text(url: str, html: str) -> tuple[str, str]:\n",
    "  downloaded = trafilatura.extract(html, include_comments=False, include_tables=True, favor_precision=True)\n",
    "  if downloaded and len(downloaded.strip()) > 400:\n",
    "    title = trafilatura.metadata.extract_metadata(html).title or \"\"\n",
    "    return clean_text(title), clean_text(downloaded)\n",
    "\n",
    "  soup = BeautifulSoup(html, \"lxml\")\n",
    "  for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "    tag.decompose()\n",
    "  main = soup.find(\"main\") or soup.find(\"article\") or soup.body\n",
    "  title = (soup.title.get_text(\" \", strip=True) if soup.title else \"\")\n",
    "  text = main.get_text(\"\\n\", strip=True) if main else soup.get_text(\"\\n\", strip=True)\n",
    "  text = \"\\n\".join([line for line in (l.strip() for l in text.splitlines()) if len(line) >= 3])\n",
    "  return clean_text(title), clean_text(text)\n",
    "\n",
    "# Write extracted sources as JSONL\n",
    "results = []\n",
    "with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as out:\n",
    "  for i, url in enumerate(URLS, 1):\n",
    "    try:\n",
    "      html = fetch_html(url)\n",
    "      title, text = extract_main_text(url, html)\n",
    "      domain = urlparse(url).netloc\n",
    "      sid = hashlib.sha1(url.encode(\"utf-8\")).hexdigest()[:12]\n",
    "      item = {\n",
    "        \"id\": sid,\n",
    "        \"url\": url,\n",
    "        \"domain\": domain,\n",
    "        \"title\": title,\n",
    "        \"text\": text,\n",
    "        \"retrieved_at_unix\": int(time.time()),\n",
    "        \"char_count\": len(text),\n",
    "        \"word_count\": len(text.split()),\n",
    "        \"tags\": [\"bullying\", \"emotion_regulation\", \"conflict_skills\"],\n",
    "      }\n",
    "      out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "      results.append((url, \"OK\", item[\"word_count\"]))\n",
    "      print(f\"OK  {i:02d}/{len(URLS)}  {domain}  words={item['word_count']}\")\n",
    "      time.sleep(0.4)\n",
    "    except Exception as e:\n",
    "      results.append((url, \"FAILED\", 0))\n",
    "      print(f\"ERR {i:02d}/{len(URLS)}  {url}  -> {e}\")\n",
    "\n",
    "print(\"\\nSaved:\", OUT_JSONL)\n",
    "print(\"OK:\", sum(1 for _,s,_ in results if s==\"OK\"), \"| FAILED:\", sum(1 for _,s,_ in results if s==\"FAILED\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHG1t1w8cP8u",
    "outputId": "af5ff3b6-1919-43f1-e6b4-b9f507eec396"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Hit:3 https://cli.github.com/packages stable InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,550 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
      "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,851 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.3 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,965 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [40.3 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [114 kB]\n",
      "Fetched 34.8 MB in 6s (6,036 kB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fonts-liberation is already the newest version (1:1.07.4-11).\n",
      "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
      "libasound2 set to manually installed.\n",
      "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
      "libcairo2 set to manually installed.\n",
      "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
      "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
      "libxcb1 set to manually installed.\n",
      "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
      "libxdamage1 set to manually installed.\n",
      "libxext6 is already the newest version (2:1.3.4-1build1).\n",
      "libxfixes3 is already the newest version (1:6.0.0-1).\n",
      "libxfixes3 set to manually installed.\n",
      "libxkbcommon0 is already the newest version (1.4.0-1).\n",
      "libxkbcommon0 set to manually installed.\n",
      "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
      "libxrandr2 set to manually installed.\n",
      "libcups2 is already the newest version (2.4.1op1-1ubuntu4.16).\n",
      "libcups2 set to manually installed.\n",
      "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
      "libdbus-1-3 set to manually installed.\n",
      "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
      "libdrm2 set to manually installed.\n",
      "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.3).\n",
      "libfreetype6 set to manually installed.\n",
      "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
      "libgbm1 set to manually installed.\n",
      "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.6).\n",
      "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
      "libnspr4 set to manually installed.\n",
      "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
      "libnss3 set to manually installed.\n",
      "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
      "libpango-1.0-0 set to manually installed.\n",
      "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
      "libwayland-client0 set to manually installed.\n",
      "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
      "libx11-6 set to manually installed.\n",
      "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.16).\n",
      "The following additional packages will be installed:\n",
      "  libatk1.0-data xfonts-encodings xfonts-utils\n",
      "Recommended packages:\n",
      "  fonts-ipafont-mincho fonts-tlwg-loma at-spi2-core\n",
      "The following NEW packages will be installed:\n",
      "  fonts-freefont-ttf fonts-ipafont-gothic fonts-noto-color-emoji\n",
      "  fonts-tlwg-loma-otf fonts-unifont fonts-wqy-zenhei libatk-bridge2.0-0\n",
      "  libatk1.0-0 libatk1.0-data libatspi2.0-0 libxcomposite1 xfonts-cyrillic\n",
      "  xfonts-encodings xfonts-scalable xfonts-utils\n",
      "0 upgraded, 15 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 28.6 MB of archives.\n",
      "After this operation, 68.7 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ipafont-gothic all 00303-21ubuntu1 [3,513 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.047-0ubuntu0.22.04.1 [10.0 MB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-tlwg-loma-otf all 1:0.7.3-1 [107 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-unifont all 1:14.0.01-1 [3,551 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-wqy-zenhei all 0.9.45-8 [7,472 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 xfonts-cyrillic all 1:1.0.5 [386 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-scalable all 1:1.0.3-1.2ubuntu1 [306 kB]\n",
      "Fetched 28.6 MB in 4s (7,722 kB/s)\n",
      "Selecting previously unselected package fonts-ipafont-gothic.\n",
      "(Reading database ... 117528 files and directories currently installed.)\n",
      "Preparing to unpack .../00-fonts-ipafont-gothic_00303-21ubuntu1_all.deb ...\n",
      "Unpacking fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
      "Selecting previously unselected package fonts-freefont-ttf.\n",
      "Preparing to unpack .../01-fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
      "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
      "Selecting previously unselected package fonts-noto-color-emoji.\n",
      "Preparing to unpack .../02-fonts-noto-color-emoji_2.047-0ubuntu0.22.04.1_all.deb ...\n",
      "Unpacking fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package fonts-tlwg-loma-otf.\n",
      "Preparing to unpack .../03-fonts-tlwg-loma-otf_1%3a0.7.3-1_all.deb ...\n",
      "Unpacking fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
      "Selecting previously unselected package fonts-unifont.\n",
      "Preparing to unpack .../04-fonts-unifont_1%3a14.0.01-1_all.deb ...\n",
      "Unpacking fonts-unifont (1:14.0.01-1) ...\n",
      "Selecting previously unselected package fonts-wqy-zenhei.\n",
      "Preparing to unpack .../05-fonts-wqy-zenhei_0.9.45-8_all.deb ...\n",
      "Unpacking fonts-wqy-zenhei (0.9.45-8) ...\n",
      "Selecting previously unselected package libatk1.0-data.\n",
      "Preparing to unpack .../06-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
      "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
      "Selecting previously unselected package libatk1.0-0:amd64.\n",
      "Preparing to unpack .../07-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
      "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
      "Selecting previously unselected package libatspi2.0-0:amd64.\n",
      "Preparing to unpack .../08-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
      "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
      "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
      "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
      "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
      "Selecting previously unselected package libxcomposite1:amd64.\n",
      "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
      "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
      "Selecting previously unselected package xfonts-encodings.\n",
      "Preparing to unpack .../11-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
      "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "Selecting previously unselected package xfonts-utils.\n",
      "Preparing to unpack .../12-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
      "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
      "Selecting previously unselected package xfonts-cyrillic.\n",
      "Preparing to unpack .../13-xfonts-cyrillic_1%3a1.0.5_all.deb ...\n",
      "Unpacking xfonts-cyrillic (1:1.0.5) ...\n",
      "Selecting previously unselected package xfonts-scalable.\n",
      "Preparing to unpack .../14-xfonts-scalable_1%3a1.0.3-1.2ubuntu1_all.deb ...\n",
      "Unpacking xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
      "Setting up fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
      "Setting up fonts-wqy-zenhei (0.9.45-8) ...\n",
      "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
      "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
      "Setting up fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
      "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
      "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
      "Setting up fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
      "update-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\n",
      "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
      "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
      "Setting up fonts-unifont (1:14.0.01-1) ...\n",
      "Setting up xfonts-utils (1:7.7+6build2) ...\n",
      "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
      "Setting up xfonts-cyrillic (1:1.0.5) ...\n",
      "Setting up xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Selecting previously unselected package libgtk-3-common.\n",
      "(Reading database ... 117823 files and directories currently installed.)\n",
      "Preparing to unpack .../libgtk-3-common_3.24.33-1ubuntu2.2_all.deb ...\n",
      "Unpacking libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
      "Selecting previously unselected package libgtk-3-0:amd64.\n",
      "Preparing to unpack .../libgtk-3-0_3.24.33-1ubuntu2.2_amd64.deb ...\n",
      "Unpacking libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
      "Selecting previously unselected package libgtk-3-bin.\n",
      "Preparing to unpack .../libgtk-3-bin_3.24.33-1ubuntu2.2_amd64.deb ...\n",
      "Unpacking libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
      "Selecting previously unselected package librsvg2-common:amd64.\n",
      "Preparing to unpack .../librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
      "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
      "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
      "Setting up libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
      "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
      "Setting up libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
      "Setting up libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "SKIP 01/8  www.stopbullying.gov  status=403  words=15\n",
      "SKIP 02/8  www.stopbullying.gov  status=403  words=15\n",
      "SKIP 03/8  www.stopbullying.gov  status=403  words=15\n",
      "SKIP 04/8  www.stopbullying.gov  status=403  words=15\n",
      "OK   05/8  stacks.cdc.gov  status=200  words=527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trafilatura.core:discarding data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP 06/8  www.apa.org  status=200  words=6\n",
      "OK   07/8  www.apa.org  status=200  words=482\n",
      "OK   08/8  www.apa.org  status=200  words=963\n",
      "\n",
      "Updated: /content/research_agent/sources_web.jsonl | total_sources = 8 | newly_ok = 3\n"
     ]
    }
   ],
   "source": [
    "# Install system libraries required by headless Chromium\n",
    "!playwright install-deps chromium || true\n",
    "!apt-get -qq update || true\n",
    "!apt-get -qq install -y libatk1.0-0 libatk-bridge2.0-0 libgtk-3-0 libcups2 libxkbcommon0 \\\n",
    "  libxcomposite1 libxdamage1 libxrandr2 libgbm1 libpangocairo-1.0-0 libpango-1.0-0 \\\n",
    "  libnss3 libnspr4 libdrm2 libxshmfence1 libasound2 || true\n",
    "\n",
    "# Import utilities\n",
    "import os, json, time, re, hashlib, asyncio\n",
    "from urllib.parse import urlparse\n",
    "import trafilatura\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "WORKDIR = \"/content/research_agent\"\n",
    "OUT_JSONL = os.path.join(WORKDIR, \"sources_web.jsonl\")\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n",
    "\n",
    "UA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "\n",
    "# Define URLs to retry (previously blocked or extracted empty)\n",
    "RETRY_URLS = [\n",
    "  \"https://www.stopbullying.gov/bullying/what-is-bullying\",\n",
    "  \"https://www.stopbullying.gov/prevention/how-to-prevent-bullying\",\n",
    "  \"https://www.stopbullying.gov/kids/what-you-can-do\",\n",
    "  \"https://www.stopbullying.gov/resources/get-help-now\",\n",
    "  \"https://stacks.cdc.gov/view/cdc/21596\",\n",
    "  \"https://www.apa.org/topics/bullying\",\n",
    "  \"https://www.apa.org/topics/bullying/prevent\",\n",
    "  \"https://www.apa.org/ed/schools/primer/bullying\",\n",
    "]\n",
    "\n",
    "# Clean extracted text\n",
    "def clean_text(t: str) -> str:\n",
    "  t = re.sub(r\"\\r\", \"\\n\", t or \"\")\n",
    "  t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "  t = re.sub(r\"[ \\t]{2,}\", \" \", t)\n",
    "  return t.strip()\n",
    "\n",
    "# Extract main text from HTML\n",
    "def extract_main_text(html: str):\n",
    "  extracted = trafilatura.extract(html, include_comments=False, include_tables=True, favor_precision=True)\n",
    "  if extracted and len(extracted.strip()) > 400:\n",
    "    md = trafilatura.metadata.extract_metadata(html)\n",
    "    title = (md.title or \"\") if md else \"\"\n",
    "    return clean_text(title), clean_text(extracted)\n",
    "\n",
    "  soup = BeautifulSoup(html, \"lxml\")\n",
    "  for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "    tag.decompose()\n",
    "  title = soup.title.get_text(\" \", strip=True) if soup.title else \"\"\n",
    "  main = soup.find(\"main\") or soup.find(\"article\") or soup.body\n",
    "  text = main.get_text(\"\\n\", strip=True) if main else soup.get_text(\"\\n\", strip=True)\n",
    "  text = \"\\n\".join([line for line in (l.strip() for l in text.splitlines()) if len(line) >= 3])\n",
    "  return clean_text(title), clean_text(text)\n",
    "\n",
    "# Load existing JSONL to update entries and avoid duplicates\n",
    "existing = {}\n",
    "if os.path.exists(OUT_JSONL):\n",
    "  with open(OUT_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "      if line.strip():\n",
    "        obj = json.loads(line)\n",
    "        existing[obj[\"url\"]] = obj\n",
    "\n",
    "async def run_render_ingest():\n",
    "  async with async_playwright() as p:\n",
    "    browser = await p.chromium.launch(\n",
    "      headless=True,\n",
    "      args=[\"--no-sandbox\", \"--disable-dev-shm-usage\"]\n",
    "    )\n",
    "    context = await browser.new_context(\n",
    "      user_agent=UA,\n",
    "      locale=\"en-US\",\n",
    "      viewport={\"width\": 1280, \"height\": 720},\n",
    "      extra_http_headers={\"Accept-Language\": \"en-US,en;q=0.9\"},\n",
    "    )\n",
    "    page = await context.new_page()\n",
    "\n",
    "    ok_count = 0\n",
    "    for i, url in enumerate(RETRY_URLS, 1):\n",
    "      try:\n",
    "        resp = await page.goto(url, wait_until=\"domcontentloaded\", timeout=60_000)\n",
    "        status = resp.status if resp else None\n",
    "        await page.wait_for_timeout(1200)\n",
    "        html = await page.content()\n",
    "\n",
    "        title, text = extract_main_text(html)\n",
    "        wc = len(text.split())\n",
    "        domain = urlparse(url).netloc\n",
    "        sid = hashlib.sha1(url.encode(\"utf-8\")).hexdigest()[:12]\n",
    "\n",
    "        if wc < 250:\n",
    "          print(f\"SKIP {i:02d}/{len(RETRY_URLS)}  {domain}  status={status}  words={wc}\")\n",
    "          continue\n",
    "\n",
    "        existing[url] = {\n",
    "          \"id\": sid,\n",
    "          \"url\": url,\n",
    "          \"domain\": domain,\n",
    "          \"title\": title,\n",
    "          \"text\": text,\n",
    "          \"retrieved_at_unix\": int(time.time()),\n",
    "          \"char_count\": len(text),\n",
    "          \"word_count\": wc,\n",
    "          \"tags\": [\"bullying\", \"emotion_regulation\", \"conflict_skills\"],\n",
    "          \"fetch_mode\": \"playwright_async_render\",\n",
    "          \"http_status\": status,\n",
    "        }\n",
    "        ok_count += 1\n",
    "        print(f\"OK   {i:02d}/{len(RETRY_URLS)}  {domain}  status={status}  words={wc}\")\n",
    "      except Exception as e:\n",
    "        print(f\"ERR  {i:02d}/{len(RETRY_URLS)}  {url}  -> {e}\")\n",
    "\n",
    "    await context.close()\n",
    "    await browser.close()\n",
    "\n",
    "  with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for obj in existing.values():\n",
    "      f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "  print(\"\\nUpdated:\", OUT_JSONL, \"| total_sources =\", len(existing), \"| newly_ok =\", ok_count)\n",
    "\n",
    "await run_render_ingest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urfqAbuJfXFv",
    "outputId": "7dd08ea5-36e4-4ce4-ba4f-f61125a55283"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 19 0 (offset 0)\n",
      "WARNING:pypdf._reader:incorrect startxref pointer(1)\n",
      "WARNING:pypdf._reader:parsing for Object Streams\n",
      "WARNING:pypdf._reader:Cannot find \"/Root\" key in trailer\n",
      "WARNING:pypdf._reader:Searching object with \"/Catalog\" key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "OUTDIR = /content/research_agent/bulk_sources\n",
      "MANIFEST = /content/research_agent/bulk_sources/manifests/bulk_manifest_1765995170.json\n",
      "OK = 164 | FAILED = 3\n",
      "PDFs counted = 285 | Est. pages = 1890\n"
     ]
    }
   ],
   "source": [
    "# Create bulk source pack (CBT + assertiveness + emotional regulation + anti-bullying) and estimate total pages\n",
    "import os, re, json, time, hashlib, zipfile\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WORKDIR = \"/content/research_agent\"\n",
    "OUTDIR  = os.path.join(WORKDIR, \"bulk_sources\")\n",
    "ZDIR    = os.path.join(OUTDIR, \"zips\")\n",
    "PDIR    = os.path.join(OUTDIR, \"pdfs\")\n",
    "MDIR    = os.path.join(OUTDIR, \"manifests\")\n",
    "os.makedirs(ZDIR, exist_ok=True); os.makedirs(PDIR, exist_ok=True); os.makedirs(MDIR, exist_ok=True)\n",
    "\n",
    "UA = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\"\n",
    "HDRS = {\"User-Agent\": UA, \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"Accept-Language\": \"en-US,en;q=0.9\"}\n",
    "TIMEOUT = 60\n",
    "\n",
    "def sha1_file(path, chunk=1024*1024):\n",
    "  h = hashlib.sha1()\n",
    "  with open(path, \"rb\") as f:\n",
    "    while True:\n",
    "      b = f.read(chunk)\n",
    "      if not b: break\n",
    "      h.update(b)\n",
    "  return h.hexdigest()\n",
    "\n",
    "def safe_name(s):\n",
    "  s = re.sub(r\"[^a-zA-Z0-9._-]+\", \"_\", s.strip())\n",
    "  return s[:180] if len(s) > 180 else s\n",
    "\n",
    "def download(url, dest_path, tries=3):\n",
    "  if os.path.exists(dest_path) and os.path.getsize(dest_path) > 1024:\n",
    "    return {\"ok\": True, \"skipped\": True, \"path\": dest_path, \"bytes\": os.path.getsize(dest_path)}\n",
    "  last_err = None\n",
    "  for k in range(tries):\n",
    "    try:\n",
    "      r = requests.get(url, headers=HDRS, stream=True, timeout=TIMEOUT, allow_redirects=True)\n",
    "      r.raise_for_status()\n",
    "      tmp = dest_path + \".part\"\n",
    "      with open(tmp, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024*256):\n",
    "          if chunk: f.write(chunk)\n",
    "      os.replace(tmp, dest_path)\n",
    "      return {\"ok\": True, \"skipped\": False, \"path\": dest_path, \"bytes\": os.path.getsize(dest_path)}\n",
    "    except Exception as e:\n",
    "      last_err = str(e)\n",
    "      time.sleep(1.2 * (k + 1))\n",
    "  return {\"ok\": False, \"error\": last_err, \"path\": dest_path}\n",
    "\n",
    "def harvest_cci_assets(label, page_url):\n",
    "  try:\n",
    "    r = requests.get(page_url, headers=HDRS, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    hrefs = []\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "      href = a.get(\"href\", \"\").strip()\n",
    "      if not href: continue\n",
    "      full = urljoin(page_url, href)\n",
    "      if \"cci.health.wa.gov.au\" not in urlparse(full).netloc:\n",
    "        continue\n",
    "      if any(full.lower().endswith(ext) for ext in [\".zip\", \".pdf\"]):\n",
    "        hrefs.append(full)\n",
    "    hrefs = sorted(set(hrefs))\n",
    "    return {\"label\": label, \"page\": page_url, \"assets\": hrefs, \"ok\": True}\n",
    "  except Exception as e:\n",
    "    return {\"label\": label, \"page\": page_url, \"assets\": [], \"ok\": False, \"error\": str(e)}\n",
    "\n",
    "# Choose “index pages” that usually expose “Download the entire workbook” ZIPs + module PDFs\n",
    "CCI_PAGES = [\n",
    "  (\"cci_assertiveness\",        \"https://www.cci.health.wa.gov.au/resources/looking-after-yourself/assertiveness\"),\n",
    "  (\"cci_worry_rumination\",     \"https://www.cci.health.wa.gov.au/resources/looking-after-yourself/worry-and-rumination\"),\n",
    "  (\"cci_tolerating_distress\",  \"https://www.cci.health.wa.gov.au/resources/looking-after-yourself/tolerating-distress\"),\n",
    "  (\"cci_social_anxiety\",       \"https://www.cci.health.wa.gov.au/resources/looking-after-yourself/social-anxiety\"),\n",
    "  (\"cci_self_esteem\",          \"https://www.cci.health.wa.gov.au/resources/looking-after-yourself/self-esteem\"),\n",
    "  (\"cci_perfectionism\",        \"https://www.cci.health.wa.gov.au/resources/looking-after-yourself/perfectionism\"),\n",
    "  (\"cci_self_compassion\",      \"https://www.cci.health.wa.gov.au/resources/looking-after-yourself/self-compassion\"),\n",
    "  (\"cci_interpersonal_clin\",   \"https://www.cci.health.wa.gov.au/Resources/For-Clinicians/Interpersonal-Problems\"),\n",
    "]\n",
    "\n",
    "# Add extra reputable PDFs focused on bullying prevention (CDC)\n",
    "DIRECT_PDFS = [\n",
    "  (\"cdc_understanding_bullying_2016.pdf\", \"https://stacks.cdc.gov/view/cdc/41572/cdc_41572_DS1.pdf\"),\n",
    "  (\"cdc_understanding_school_violence_2016.pdf\", \"https://stacks.cdc.gov/view/cdc/43376/cdc_43376_DS1.pdf\"),\n",
    "  (\"cdc_bullying_prevention_for_educators.pdf\", \"https://www2c.cdc.gov/podcasts/media/pdf/BullyingPrevention_Educators.pdf\"),\n",
    "  (\"cdc_school_based_anti_bullying_interventions.pdf\", \"https://stacks.cdc.gov/view/cdc/168632/cdc_168632_DS4.pdf\"),\n",
    "  (\"cdc_youth_violence_technical_package_spanish.pdf\", \"https://www.cdc.gov/violenceprevention/pdf/yv-technicalpackage-spanish.pdf\"),\n",
    "]\n",
    "\n",
    "manifest = {\"harvest\": [], \"downloads\": [], \"unzips\": [], \"summary\": {}}\n",
    "\n",
    "# Harvest assets from CCI pages\n",
    "all_assets = []\n",
    "for label, page in CCI_PAGES:\n",
    "  info = harvest_cci_assets(label, page)\n",
    "  manifest[\"harvest\"].append(info)\n",
    "  all_assets.extend([(label, u) for u in info.get(\"assets\", [])])\n",
    "\n",
    "# Download assets (ZIPs and PDFs)\n",
    "ok, fail = 0, 0\n",
    "for label, url in all_assets:\n",
    "  fname = safe_name(os.path.basename(urlparse(url).path) or (label + \".bin\"))\n",
    "  target_dir = ZDIR if fname.lower().endswith(\".zip\") else PDIR\n",
    "  dest = os.path.join(target_dir, f\"{label}__{fname}\")\n",
    "  res = download(url, dest)\n",
    "  rec = {\"label\": label, \"url\": url, \"file\": dest, **{k:v for k,v in res.items() if k in [\"ok\",\"skipped\",\"bytes\",\"error\"]}}\n",
    "  if res.get(\"ok\"):\n",
    "    rec[\"sha1\"] = sha1_file(dest)[:12]\n",
    "    ok += 1\n",
    "  else:\n",
    "    fail += 1\n",
    "  manifest[\"downloads\"].append(rec)\n",
    "\n",
    "# Download direct CDC PDFs\n",
    "for fname, url in DIRECT_PDFS:\n",
    "  dest = os.path.join(PDIR, fname)\n",
    "  res = download(url, dest)\n",
    "  rec = {\"label\": \"direct_pdf\", \"url\": url, \"file\": dest, **{k:v for k,v in res.items() if k in [\"ok\",\"skipped\",\"bytes\",\"error\"]}}\n",
    "  if res.get(\"ok\"):\n",
    "    rec[\"sha1\"] = sha1_file(dest)[:12]\n",
    "    ok += 1\n",
    "  else:\n",
    "    fail += 1\n",
    "  manifest[\"downloads\"].append(rec)\n",
    "\n",
    "# Unzip any ZIPs into structured folders\n",
    "for d in list(manifest[\"downloads\"]):\n",
    "  if not d.get(\"ok\"):\n",
    "    continue\n",
    "  if not str(d.get(\"file\",\"\")).lower().endswith(\".zip\"):\n",
    "    continue\n",
    "  zip_path = d[\"file\"]\n",
    "  out_sub = os.path.join(PDIR, safe_name(os.path.splitext(os.path.basename(zip_path))[0]))\n",
    "  os.makedirs(out_sub, exist_ok=True)\n",
    "  try:\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "      z.extractall(out_sub)\n",
    "    manifest[\"unzips\"].append({\"zip\": zip_path, \"to\": out_sub, \"ok\": True})\n",
    "  except Exception as e:\n",
    "    manifest[\"unzips\"].append({\"zip\": zip_path, \"to\": out_sub, \"ok\": False, \"error\": str(e)})\n",
    "\n",
    "# Estimate total pages across all PDFs gathered so far\n",
    "try:\n",
    "  from pypdf import PdfReader\n",
    "  pdf_paths = []\n",
    "  for root, _, files in os.walk(WORKDIR):\n",
    "    for f in files:\n",
    "      if f.lower().endswith(\".pdf\"):\n",
    "        pdf_paths.append(os.path.join(root, f))\n",
    "  total_pages = 0\n",
    "  counted = 0\n",
    "  for p in pdf_paths:\n",
    "    try:\n",
    "      total_pages += len(PdfReader(p).pages)\n",
    "      counted += 1\n",
    "    except Exception:\n",
    "      pass\n",
    "  manifest[\"summary\"] = {\n",
    "    \"workdir\": WORKDIR,\n",
    "    \"bulk_outdir\": OUTDIR,\n",
    "    \"pdf_files_counted\": counted,\n",
    "    \"total_estimated_pages\": total_pages,\n",
    "    \"downloads_ok\": ok,\n",
    "    \"downloads_failed\": fail,\n",
    "  }\n",
    "except Exception as e:\n",
    "  manifest[\"summary\"] = {\"error\": str(e), \"downloads_ok\": ok, \"downloads_failed\": fail}\n",
    "\n",
    "# Save manifest\n",
    "out_json = os.path.join(MDIR, f\"bulk_manifest_{int(time.time())}.json\")\n",
    "with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "  json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"DONE\")\n",
    "print(\"OUTDIR =\", OUTDIR)\n",
    "print(\"MANIFEST =\", out_json)\n",
    "print(\"OK =\", manifest[\"summary\"].get(\"downloads_ok\"), \"| FAILED =\", manifest[\"summary\"].get(\"downloads_failed\"))\n",
    "print(\"PDFs counted =\", manifest[\"summary\"].get(\"pdf_files_counted\"), \"| Est. pages =\", manifest[\"summary\"].get(\"total_estimated_pages\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597,
     "referenced_widgets": [
      "8f27a24355fb4ef1bffea34507018a2a",
      "bf14ac0cca5e4f6883725f1653a07b84",
      "5bb0b9ebdd9446ceb677636929e9f0a9",
      "bd370e7f9dd5457fb36267f151e104b5",
      "0846e4e5fc7c4d4583f60354bec001d1",
      "969e3e0f354e4dc4ac75f92f9108a83d",
      "926e35b6f89c41ca8b5110775122e288",
      "10a059c36c954a7bb8d69120f2f07d8e",
      "22b0d96d5e4a4111aa3fba475ccb0ec9",
      "e9a3d019a3434e1499b710cc2fb4ff22",
      "b446af79367e45f485c0bd4758d47260",
      "f7e968cd65f347d0b8b2c52f80c303fc",
      "770e2510a3114cdeaace328d62160b77",
      "9a5a30f8468841769f91a9df58d29d84",
      "5b4a6122b67f42598b010bcd7d4a2aa1",
      "f53c434ba8044d99ae656a9d113ab0cc",
      "ac4d45e782f54ae2b8b1425601354191",
      "d87088456f8542c39131e7acad952976",
      "7cfee7f44dad401f8300e135669bd8f7",
      "d7a81f7959b04d5abc23b694785bb61b",
      "b00e12643a1247e59441ce4dd6b2b8a7",
      "f7f74fb021f14a109cb5cc3122ff9ee3",
      "2bc3f51e75de4b50a7f290c4be50b247",
      "7fbd89e4eeaa4aeeb4f507640236da9e",
      "58e164076a194760a4ee5035181a5e12",
      "fefc56763bc94e2fb565f3d0a0224024",
      "ad7f7b5dd5e94da1a8513ad2c827ab17",
      "d89c5353e91e48e395a2f2f8562e88a2",
      "fdfa833fb61a4160bef84cc058ef73dc",
      "559e53456b484f7e908cf489499d6357",
      "9857c46678ca4415b95b66897aca2eb6",
      "a057b615ef90402ca9619c0bb8d7d53f",
      "d2692b7b059743e3b6d2f9a46877f7e0",
      "41b7575af1cf48c2b5b97561317ff8b0",
      "31630713e9724140a9f8275f0b74d571",
      "7989e35cc126472d8f828ab31aacdb7f",
      "669ea218b7bf4a5bbec96b54711ee3ea",
      "06023eddd65a43eeabb8c71b18027fe0",
      "1c7d5a5e21234d42ac140f4142b8f90c",
      "85ffb9f5bb144c20be6beaf7b9ea7717",
      "9b2c5c73db57474c8123e5e2fc4ab036",
      "30be9253544f43e5bf96b615a210e8e3",
      "a81a097973ff4009b715d92939f27453",
      "f1a8a8d24693493e8319623a882bac6e",
      "7b4ea9ee0b0e4912a130a0054e78a4cc",
      "bd070f6512e848e48b3f270c93108e14",
      "c99a2d70d0ce4fb282138f41198813b4",
      "b3b7867e62214de7ac4d50becdcb7b71",
      "e22cd311ac0b459a92f6f42e6f0f7d6c",
      "c663a9c729cd4b319e3af1b62beb472c",
      "87b4e926cc2e4c9b97967870678db314",
      "8a6fd912e18c4b06bd000350c2de70ec",
      "8500f969f9d34fb1b6e175b9b957383f",
      "372283c6465d4317af60d5011e5569ac",
      "73a54deefcaa483a8f6a058667147172",
      "92c5a30619df4483b664a4b0dc504c0c",
      "c25c6c672eb640cfb9757726293b4d15",
      "1c27df9a6c044a9786db9d715ecb1bfd",
      "e53901f8362642b791ca232c7ccb693e",
      "49788b5239bf43c89e22aa521c5a450d",
      "747b295b02c34ff48abaef1def270c16",
      "f3e274c2f7fb404cb191f3a69f54a721",
      "ef16b8a248cc465ea8a4e7b962a19014",
      "91807bbf2827469cbbaa908078674ac9",
      "0d6ecefe55aa432db0e22f7a528a49df",
      "6ab94aa939a94c099f1d4cf2a62b2f49",
      "0ebc8f5859bb4598b1593b843c8d0230",
      "fcd5acc9ac064daea0edfa6173a5f7d1",
      "4583ad5eb3974e3bac98ee955d1d725c",
      "d1864d25fabf4de3aa2d88e77af9a4f9",
      "14bfc43305824a8499f8e1b96115468a",
      "b3d72edd1696405e8610eb48305391c0",
      "b1af8af5c4db4e39a02e0aee6737df21",
      "aa0f67fb8eb04445a5f1e68e5be56d72",
      "efb3545949ec4934a8d0c7158ea44e21",
      "c7a5810ed0e344c091066e6929985321",
      "115f0db4aa2e47a491a78f012775379a",
      "3d84a00ae36d4a9eb635642b9c813a8d",
      "ec880eacfaa747cb821f3c7971b77f80",
      "0ec7e95e2d774be79f2c1d9127fe4c0e",
      "234b3ddc1c424080bb7dfc5414462d55",
      "e9e14a77942f4afd9fa996e196c9b4a4",
      "b3df362ac38a4c0aa0658ecb5163bd29",
      "89e37ab87a7f4f0db551ec5828936b9a",
      "47650a1437744cef943c6de73d920616",
      "f22873bbb93b45588f24cc1831dec189",
      "9918ff4a8b6745a9af7a45de5a1bb3f5",
      "d617be40c85d4f67a1179669f40ec260",
      "7e2c8a2008c44a888d6fe628e791cd21",
      "19407f69782d40c7b857f8327e8976f2",
      "745d00f1a34d4178b983a2d2c1324db1",
      "c0b73c9a36884a9299e37c1837081ece",
      "d0334a0bcd494f4aa0667a42301705ab",
      "877bf61a7d4f4722bf9f44c9bfada0f2",
      "7a486c2bbbcf4a7aad632b1532eb3068",
      "e49a2c7858234fbd9e35d918bdbcfdee",
      "ad93b69897ed42dea2fd9b6db5d5ed1e",
      "b3c5c690e70648458a67a83a705e813c",
      "1219ff99296140e5a5f74502b4f50b3d",
      "70685784d7ef4f97b5d7eff3531fae6f",
      "3cc0f754460c435090c159e0fb40e015",
      "1201349aff8d4cd7894f891b4f469329",
      "1bf9eacbea38431eb1279d450d445924",
      "0978a6e3b5914a7c96c1eb19253ac1eb",
      "82fdb62f9bde4d89b6a05fdbeeed3f71",
      "23d288627987415d9fcfe5d7222213c8",
      "ac66bde60c40450db5eef697e612452f",
      "7e724e82342e48fdaa88360d8d3c5fd1",
      "4e14c33c41f544f1952e1d4879139f3f",
      "0b350bbb6f2a4bed94a3b5d4a633566e",
      "c35c7981066d4c8aafb333566a7f33f6",
      "040b290337ad40ba9975805b9f007866",
      "3866e2ae799147f1a8afbb6e269c1f48",
      "960956e05d4f415e8fbdfb05603eb90a",
      "669d4f9b709c48e5b602e1701b7123cb",
      "9cd8bf27fcfe4825b066c6b2076864fe",
      "cf82ed68c1b14715b426e15e5f49445f",
      "f98f11683e4e4cd0a27b1f65fcb88085",
      "3b332f69fa4d435ba21c167b0312c7b1",
      "6b9321f45c7e4b0cb3bd90663ff51699",
      "88ac9db6531f41608d1a1ff17050b2c5"
     ]
    },
    "id": "8aBKlB9Klv6o",
    "outputId": "7393555b-6ec9-47b3-cc88-30e594423ca9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f27a24355fb4ef1bffea34507018a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e968cd65f347d0b8b2c52f80c303fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc3f51e75de4b50a7f290c4be50b247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b7575af1cf48c2b5b97561317ff8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4ea9ee0b0e4912a130a0054e78a4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c5a30619df4483b664a4b0dc504c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebc8f5859bb4598b1593b843c8d0230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d84a00ae36d4a9eb635642b9c813a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2c8a2008c44a888d6fe628e791cd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70685784d7ef4f97b5d7eff3531fae6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35c7981066d4c8aafb333566a7f33f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "PDF files seen = 286 | Web sources seen = 7\n",
      "Total chunks = 4018 | Dim = 384\n",
      "Saved: /content/research_agent/rag_store/faiss.index\n",
      "Saved: /content/research_agent/rag_store/chunks.jsonl\n",
      "Saved: /content/research_agent/rag_store/manifest.json\n"
     ]
    }
   ],
   "source": [
    "# Build RAG store from PDFs + sources_web.jsonl, then save FAISS index + chunks metadata\n",
    "\n",
    "import os, re, json, time, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "import fitz  # PyMuPDF\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "WORKDIR = Path(\"/content/research_agent\")\n",
    "SOURCES_WEB = WORKDIR / \"sources_web.jsonl\"\n",
    "\n",
    "RAGDIR = WORKDIR / \"rag_store\"\n",
    "INDEX_PATH = RAGDIR / \"faiss.index\"\n",
    "CHUNKS_PATH = RAGDIR / \"chunks.jsonl\"\n",
    "MANIFEST_PATH = RAGDIR / \"manifest.json\"\n",
    "\n",
    "RESET = True\n",
    "EMBED_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "CHUNK_CHARS = 1400\n",
    "OVERLAP_CHARS = 220\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MAX_PDFS = None          # Set to an integer to limit\n",
    "MAX_PAGES_PER_PDF = None # Set to an integer to limit\n",
    "\n",
    "def clean_text(t: str) -> str:\n",
    "    t = (t or \"\").replace(\"\\x00\", \" \")\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
    "    return t.strip()\n",
    "\n",
    "def chunk_text(t: str, chunk_chars: int, overlap_chars: int):\n",
    "    t = clean_text(t)\n",
    "    if len(t) < 120:\n",
    "        return []\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(t)\n",
    "    while start < n:\n",
    "        end = min(n, start + chunk_chars)\n",
    "        if end < n:\n",
    "            cut = t.rfind(\"\\n\\n\", start, end)\n",
    "            if cut != -1 and cut > start + int(chunk_chars * 0.6):\n",
    "                end = cut\n",
    "        chunk = t[start:end].strip()\n",
    "        if len(chunk) >= 200:\n",
    "            chunks.append(chunk)\n",
    "        if end >= n:\n",
    "            break\n",
    "        start = max(0, end - overlap_chars)\n",
    "    return chunks\n",
    "\n",
    "def iter_pdfs(root: Path):\n",
    "    pdfs = sorted([p for p in root.rglob(\"*.pdf\")])\n",
    "    if MAX_PDFS is not None:\n",
    "        pdfs = pdfs[:MAX_PDFS]\n",
    "    for pdf_path in pdfs:\n",
    "        yield pdf_path\n",
    "\n",
    "def extract_pdf_pages(pdf_path: Path):\n",
    "    doc = fitz.open(str(pdf_path))\n",
    "    page_count = doc.page_count\n",
    "    if MAX_PAGES_PER_PDF is not None:\n",
    "        page_count = min(page_count, MAX_PAGES_PER_PDF)\n",
    "    for i in range(page_count):\n",
    "        page = doc.load_page(i)\n",
    "        txt = page.get_text(\"text\")\n",
    "        txt = clean_text(txt)\n",
    "        if len(txt) < 120:\n",
    "            continue\n",
    "        yield (i + 1, txt)\n",
    "    doc.close()\n",
    "\n",
    "def iter_web_sources(jsonl_path: Path):\n",
    "    if not jsonl_path.exists():\n",
    "        return\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except:\n",
    "                continue\n",
    "            text = clean_text(obj.get(\"text\", \"\"))\n",
    "            if len(text) < 200:\n",
    "                continue\n",
    "            yield obj\n",
    "\n",
    "if RESET and RAGDIR.exists():\n",
    "    shutil.rmtree(RAGDIR)\n",
    "RAGDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model = SentenceTransformer(EMBED_MODEL)\n",
    "dim = model.get_sentence_embedding_dimension()\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "total_chunks = 0\n",
    "pdf_files = 0\n",
    "web_sources = 0\n",
    "t0 = time.time()\n",
    "\n",
    "def write_chunk(fp, meta: dict, text: str):\n",
    "    rec = {\"meta\": meta, \"text\": text}\n",
    "    fp.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(CHUNKS_PATH, \"w\", encoding=\"utf-8\") as out:\n",
    "    buffer_texts = []\n",
    "    buffer_metas = []\n",
    "\n",
    "    # Ingest web sources\n",
    "    for obj in iter_web_sources(SOURCES_WEB) or []:\n",
    "        web_sources += 1\n",
    "        url = obj.get(\"url\", \"\")\n",
    "        title = obj.get(\"title\", \"\")\n",
    "        domain = obj.get(\"domain\", \"\")\n",
    "        chunks = chunk_text(obj.get(\"text\", \"\"), CHUNK_CHARS, OVERLAP_CHARS)\n",
    "        for ci, ch in enumerate(chunks, 1):\n",
    "            meta = {\n",
    "                \"source_type\": \"web\",\n",
    "                \"url\": url,\n",
    "                \"domain\": domain,\n",
    "                \"title\": title,\n",
    "                \"chunk_index\": ci,\n",
    "            }\n",
    "            buffer_texts.append(ch)\n",
    "            buffer_metas.append(meta)\n",
    "\n",
    "            if len(buffer_texts) >= BATCH_SIZE:\n",
    "                emb = model.encode(buffer_texts, batch_size=BATCH_SIZE, normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "                index.add(emb)\n",
    "                for m, tx in zip(buffer_metas, buffer_texts):\n",
    "                    write_chunk(out, m, tx)\n",
    "                total_chunks += len(buffer_texts)\n",
    "                buffer_texts, buffer_metas = [], []\n",
    "\n",
    "    # Ingest PDFs\n",
    "    for pdf_path in iter_pdfs(WORKDIR):\n",
    "        pdf_files += 1\n",
    "        rel = str(pdf_path.relative_to(WORKDIR))\n",
    "        try:\n",
    "            for page_num, page_text in extract_pdf_pages(pdf_path):\n",
    "                chunks = chunk_text(page_text, CHUNK_CHARS, OVERLAP_CHARS)\n",
    "                for ci, ch in enumerate(chunks, 1):\n",
    "                    meta = {\n",
    "                        \"source_type\": \"pdf\",\n",
    "                        \"file\": rel,\n",
    "                        \"page\": page_num,\n",
    "                        \"chunk_index\": ci,\n",
    "                    }\n",
    "                    buffer_texts.append(ch)\n",
    "                    buffer_metas.append(meta)\n",
    "\n",
    "                    if len(buffer_texts) >= BATCH_SIZE:\n",
    "                        emb = model.encode(buffer_texts, batch_size=BATCH_SIZE, normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "                        index.add(emb)\n",
    "                        for m, tx in zip(buffer_metas, buffer_texts):\n",
    "                            write_chunk(out, m, tx)\n",
    "                        total_chunks += len(buffer_texts)\n",
    "                        buffer_texts, buffer_metas = [], []\n",
    "        except Exception as e:\n",
    "            print(\"SKIP PDF (read error):\", rel, \"->\", e)\n",
    "\n",
    "    # Flush remaining\n",
    "    if buffer_texts:\n",
    "        emb = model.encode(buffer_texts, batch_size=BATCH_SIZE, normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "        index.add(emb)\n",
    "        for m, tx in zip(buffer_metas, buffer_texts):\n",
    "            write_chunk(out, m, tx)\n",
    "        total_chunks += len(buffer_texts)\n",
    "\n",
    "faiss.write_index(index, str(INDEX_PATH))\n",
    "\n",
    "manifest = {\n",
    "    \"created_at_unix\": int(time.time()),\n",
    "    \"workdir\": str(WORKDIR),\n",
    "    \"ragdir\": str(RAGDIR),\n",
    "    \"embed_model\": EMBED_MODEL,\n",
    "    \"faiss_index\": str(INDEX_PATH),\n",
    "    \"chunks_jsonl\": str(CHUNKS_PATH),\n",
    "    \"embedding_dim\": dim,\n",
    "    \"chunk_chars\": CHUNK_CHARS,\n",
    "    \"overlap_chars\": OVERLAP_CHARS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"pdf_files_seen\": pdf_files,\n",
    "    \"web_sources_seen\": web_sources,\n",
    "    \"total_chunks\": total_chunks,\n",
    "    \"elapsed_sec\": round(time.time() - t0, 2),\n",
    "}\n",
    "with open(MANIFEST_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"DONE\")\n",
    "print(\"PDF files seen =\", pdf_files, \"| Web sources seen =\", web_sources)\n",
    "print(\"Total chunks =\", total_chunks, \"| Dim =\", dim)\n",
    "print(\"Saved:\", INDEX_PATH)\n",
    "print(\"Saved:\", CHUNKS_PATH)\n",
    "print(\"Saved:\", MANIFEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276,
     "referenced_widgets": [
      "de51c6f9126d4cd19517882e2a868422",
      "123559df1da04cc3832c74bf38a2d163",
      "05879ba1cdf849288475ebbd4a462933",
      "47f547eae6f44cefbbd65f54935ed5e5",
      "2bfb9dcfc92448b885d37c2fb87fbd88",
      "5fe109cc383840a984822b96868b3735",
      "2feeb67742aa47a3a90968c949c263de",
      "a2225271e74245349075d5b9e899061b",
      "bfd040856a28472d9aabdcf022560b0f",
      "12e77dcfe5ba4fbf8c993d524187af2b",
      "fe403ca9da864d28a0667f5ed5bec3f4",
      "ab9c48a97544472781f26ce5e9f2e965",
      "64b61484390645dc96c64b4f5efb0345",
      "9dab19a9ef0042b494954889212b3f0e",
      "4210f523879349ccb737af36b0ec8d2e",
      "200fbe0ce6614217be2d6afbd9c51f24",
      "ff58851bdbd34d9ea0ecbdc1f47a8b6d",
      "20493c2a50fc49a582a846ecb3ca394f",
      "5fd04c28a7cd46eb97ce333892713fe3",
      "1ed6ee4e2d3f48fcb0a09258833f5135",
      "720f79346f4243a4a9590201aee6b209",
      "3c808c5769a6499e8c47f72110a4afc9",
      "16a4adc2f81249b3a3a58173fe11a51c",
      "28cf48b07e404b63a90abc7009abf022",
      "776b6983cb084f96a3b1d33e18027dcd",
      "ae66ac25b1704c08a3443288ddbcce43",
      "e0af16c7099846859fa19f2c1c9a039e",
      "4050ada729c645dd94b6bd9f3b74fc0d",
      "c9f28e74d9584af1badfd96a1316a462",
      "f6986545dc8c4004a52955ddb228d9c5",
      "b4f44526b5cc463c8c0e3026b8f4ffc5",
      "217d21dc7e69499490401c13ee41c9f6",
      "0df45df9ca0d41509708e2ddbc31aa2b",
      "2f9342a541904600b4a9b17242082bcf",
      "ae19c649e4264333aa3b3bc63da1f00b",
      "38d1c2b23db248ed8bec6dde042bfac2",
      "0fa841cefe434b14b04797dfddfcf5d6",
      "95d3141d39db4a3b86c04f52d0e64718",
      "d92771e19d314f3c9d6953366896a9b7",
      "f15d03f4b2d84418af975674af8b7dd2",
      "903f11efa182458d86535a59d09664c1",
      "383db28213ae4bd7bdf15febb383651a",
      "3edf9850e609451c98044cbc786bd1f9",
      "61775dad5ca64ff6af66dc3380ff1262",
      "8b175e06997d4aa9b0ebd6124c9dc77b",
      "a1c1830446ef47009a665c4faa311233",
      "a39fedc52cb6424d89daa3027beb02f1",
      "31f9fac4eca4492190d0371be98ac6f5",
      "058f991a782b4beab6736b8a435ef122",
      "2311a2fd7a444fff8f6f525bca02dc97",
      "3a98bc85a9da414986328ee49b4bb6b0",
      "304755f7be1a42958a6a335fe6815bf4",
      "698c55b3fcdf41c799d4e8bf4e3b29f6",
      "1f49264c69c6492c9718a3166447d715",
      "8e8d816f2c21464c85c9d7284ccfe55e",
      "4c7058d488694c0ca361fdbdd981ea09",
      "a2aac3042c4b45f6b2408d83bd2b4420",
      "468f4fb0031d4be6a64182441ea79035",
      "f19d199c03584a1287d5bc292a78f85f",
      "96192219af2d48daace7cd5539ebfc7d",
      "ebf59d8f074c4e4795ed6b95734aba79",
      "9a28c3f405ff43b088232fb8a020b238",
      "6949800713ce473c926d6f3539477e91",
      "5fd1089e0bee4144901dcf02644b24d6",
      "bcb507a747e142f195a704ab6f5ad565",
      "475d5169968940888909b1f57c7307e5",
      "f5c2871ebc044963adad16651122f7f3",
      "985bd56d4a6c421084950fd4e1ec1e67",
      "0563ffb6df30450c8a8af003099938bd",
      "eb4d30b0a52e4e7e9b010ed35c7bf292",
      "7084ac3d5c634903bb2a5b5fe75af911",
      "15a8a3231a6548349c02246bba3027da",
      "2eb34f6a577547ec995eefc98912a2cc",
      "c794d50bffe840fe820fb293f05d3ca9",
      "90fdd67f43904eb6a1ee770505a34714",
      "26d3d8c2ae2441738da7a54b16f918bb",
      "d495aee8497d43c3a2a74b18657e7fa2"
     ]
    },
    "id": "GafCRpWyx-ez",
    "outputId": "8bd9cfc8-9b42-41be-bfac-d16bb4f9721c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de51c6f9126d4cd19517882e2a868422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9c48a97544472781f26ce5e9f2e965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a4adc2f81249b3a3a58173fe11a51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9342a541904600b4a9b17242082bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b175e06997d4aa9b0ebd6124c9dc77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7058d488694c0ca361fdbdd981ea09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c2871ebc044963adad16651122f7f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY | device=cpu | chunks=4018 | llm=Qwen/Qwen2.5-1.5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "# Load RAG store paths\n",
    "import os, json, re, textwrap\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "WORKDIR = \"/content/research_agent\"\n",
    "RAGDIR = f\"{WORKDIR}/rag_store\"\n",
    "INDEX_PATH = f\"{RAGDIR}/faiss.index\"\n",
    "CHUNKS_PATH = f\"{RAGDIR}/chunks.jsonl\"\n",
    "\n",
    "# Select runtime device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Load embedder used for FAISS\n",
    "EMBED_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "# Load FAISS index and chunks\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "chunks = []\n",
    "with open(CHUNKS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    if line.strip():\n",
    "      chunks.append(json.loads(line))\n",
    "\n",
    "# Load a local instruction model\n",
    "LLM_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_NAME, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  LLM_NAME,\n",
    "  torch_dtype=DTYPE,\n",
    "  device_map=\"auto\",\n",
    "  low_cpu_mem_usage=True\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Define citation formatting\n",
    "def format_citation(meta: dict) -> str:\n",
    "  if meta.get(\"source_type\") == \"pdf\":\n",
    "    return f\"[pdf:{meta.get('file','?')}#p{meta.get('page','?')}]\"\n",
    "  if meta.get(\"source_type\") == \"web\":\n",
    "    dom = meta.get(\"domain\",\"web\")\n",
    "    return f\"[web:{dom}]\"\n",
    "  return \"[source]\"\n",
    "\n",
    "# Define retrieval\n",
    "def retrieve(query: str, k: int = 6):\n",
    "  q = (query or \"\").strip()\n",
    "  if not q:\n",
    "    return []\n",
    "  qv = embedder.encode([q], normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "  D, I = index.search(qv, k)\n",
    "  hits = []\n",
    "  for score, idx in zip(D[0].tolist(), I[0].tolist()):\n",
    "    if idx < 0 or idx >= len(chunks):\n",
    "      continue\n",
    "    hits.append({\"score\": float(score), \"meta\": chunks[idx][\"meta\"], \"text\": chunks[idx][\"text\"]})\n",
    "  return hits\n",
    "\n",
    "# Define scope gate\n",
    "SCOPE_KEYWORDS = [\n",
    "  \"bully\", \"bullying\", \"harass\", \"harassment\", \"tease\", \"teasing\", \"intimidat\", \"threat\",\n",
    "  \"anger\", \"anxiety\", \"worry\", \"stress\", \"emotion\", \"regulation\", \"cbt\", \"thought\", \"rumination\",\n",
    "  \"conflict\", \"resolution\", \"negotiat\", \"assert\", \"assertive\", \"boundary\", \"boundaries\", \"de-escalat\"\n",
    "]\n",
    "\n",
    "def is_sensitive_crisis(q: str) -> bool:\n",
    "  ql = (q or \"\").lower()\n",
    "  return any(x in ql for x in [\n",
    "    \"suicid\", \"kill myself\", \"self-harm\", \"self harm\", \"cut myself\", \"end my life\",\n",
    "    \"domestic violence\", \"partner hits\", \"abusive partner\", \"sexual assault\", \"rape\"\n",
    "  ])\n",
    "\n",
    "def is_in_scope(q: str, hits: list) -> bool:\n",
    "  ql = (q or \"\").lower()\n",
    "  kw = any(k in ql for k in SCOPE_KEYWORDS)\n",
    "  best = max([h[\"score\"] for h in hits], default=0.0)\n",
    "  return (kw and best >= 0.18) or (best >= 0.27)\n",
    "\n",
    "# Define prompt builder\n",
    "def build_prompt(question: str, hits: list) -> str:\n",
    "  packed = []\n",
    "  for h in hits:\n",
    "    cite = format_citation(h[\"meta\"])\n",
    "    snippet = textwrap.shorten(h[\"text\"].replace(\"\\n\", \" \"), width=900, placeholder=\"…\")\n",
    "    packed.append(f\"{cite} score={h['score']:.3f}\\n{snippet}\")\n",
    "  sources_block = \"\\n\\n\".join(packed)\n",
    "\n",
    "  return f\"\"\"\n",
    "You are a scope-limited assistant.\n",
    "Allowed topics: bullying prevention/response skills, CBT-based emotion regulation (anger/anxiety/stress), conflict resolution, negotiation, assertiveness, boundaries, de-escalation.\n",
    "Rule: answer ONLY using the provided sources. If sources are insufficient, say you do not have enough information and ask for a source.\n",
    "Rule: if the question is out of scope (e.g., cooking), refuse politely and say it is out of scope.\n",
    "Rule: keep advice practical, non-graphic, and appropriate for teens; encourage trusted adults/professionals when needed.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Sources:\n",
    "{sources_block}\n",
    "\n",
    "Write the answer with:\n",
    "- Clear steps or bullet points\n",
    "- Citations inline after claims, using the provided [pdf:...#p..] or [web:domain] tags\n",
    "\"\"\".strip()\n",
    "\n",
    "# Define text generation\n",
    "def generate_text(prompt: str, max_new_tokens: int = 450) -> str:\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Follow the rules exactly.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "  try:\n",
    "    inp = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "  except Exception:\n",
    "    inp = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "  inp = inp.to(model.device)\n",
    "\n",
    "  out = model.generate(\n",
    "    inp,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.08\n",
    "  )\n",
    "  txt = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "  return txt.strip()\n",
    "\n",
    "# Define single entrypoint\n",
    "def ask(question: str, k: int = 6) -> str:\n",
    "  q = (question or \"\").strip()\n",
    "  if not q:\n",
    "    return \"Ask a question.\"\n",
    "\n",
    "  if is_sensitive_crisis(q):\n",
    "    return (\"If you or someone else is in immediate danger or might self-harm, contact local emergency services \"\n",
    "            \"or a trusted adult right now. I can still help with general, non-urgent coping and communication steps, \"\n",
    "            \"but I can’t replace professional or emergency support.\")\n",
    "\n",
    "  hits = retrieve(q, k=k)\n",
    "\n",
    "  if not is_in_scope(q, hits):\n",
    "    return \"Out of scope for this agent. Ask about bullying, CBT emotion regulation, conflict resolution, or negotiation.\"\n",
    "\n",
    "  prompt = build_prompt(q, hits)\n",
    "  return generate_text(prompt)\n",
    "\n",
    "print(f\"READY | device={DEVICE} | chunks={len(chunks)} | llm={LLM_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlhKTIYq1rnF",
    "outputId": "a761bec9-fe08-4709-cf3a-67f6dccf2743"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Q1 =====\n",
      "Persona: Adult woman, 34, school counselor\n",
      "Question: Define bullying vs a one-time conflict, and list 4 signs that a situation is bullying (not just disagreement).\n",
      "\n",
      "Answer (max 10 lines):\n",
      "**Definition of Bullying vs. One-Time Conflict**\n",
      "Bullying, including cyberbullying, involves repeated actions intended to cause harm in relationships where there is a real or perceived power imbalance. It can be verbal (e.g., purposeful humiliation, teasing, threatening), physical (e.g., hitting, kicking, etc.), relational (e.g., spreading rumors, excluding from group activities), or through technology (e.g., sending mean messages, posting hurtful comments online).\n",
      "**Signs of Bullying**\n",
      "1. **Repetitive Behavior**: The bullying occurs repeatedly over time, often daily or almost daily.\n",
      "2. **Power Imbalance**: There is a significant age, gender, or status difference between the bully and the victim.\n",
      "3. **Harmful Intent**: The actions are meant to cause physical, psychological, social, or educational harm.\n",
      "4. **Unprovoked Aggression**: The victim does not provoke the behavior; it is directed towards them without provocation.\n",
      "**Comparison Between Bullying and Normal Conflict**\n",
      "Conflict is a natural part of most relationships due to differing perspectives and priorities among individuals. Unlike bullying, conflicts are generally resolved constructively through dialogue, compromise, and mutual respect. Conflicts can escalate into bullying if they become repetitive, involve a power imbalance, or\n",
      "\n",
      "Top 3 sources used:\n",
      "- [web:www.apa.org]\n",
      "- [pdf:kidpower_bullying_qa.pdf#p1]\n",
      "- [web:www.cdc.gov]\n",
      "\n",
      "===== Q2 =====\n",
      "Persona: Teen boy, 14, student\n",
      "Question: I’m being bullied at school. Give me 5 concrete things I can do this week to reduce risk and get support.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "### Steps to Reduce Risk and Get Support\n",
      "1. **Stay Calm and Confident**\n",
      "   - Take deep breaths to stay calm. Remember, you're not alone.\n",
      "   - Speak calmly and confidently when addressing the bully. Use phrases like \"Stop!\" or \"That's not okay.\"\n",
      "2. **Seek Support from Trusted Adults**\n",
      "   - Talk to a teacher, counselor, or principal about the bullying. They can help address the issue.\n",
      "   - Seek guidance from parents or guardians who can provide additional support.\n",
      "3. **Change Schools or Activities**\n",
      "   - If the bullying persists, consider moving to a new school or joining different clubs or activities.\n",
      "   - Changing environments can sometimes deter bullies.\n",
      "\n",
      "Top 3 sources used:\n",
      "- [pdf:kidpower_bullying_qa.pdf#p2]\n",
      "- [pdf:kidpower_bullying_qa.pdf#p3]\n",
      "- [pdf:kidpower_essp_evaluation_2014.pdf#p6]\n",
      "\n",
      "===== Q3 =====\n",
      "Persona: Teen girl, 16, student\n",
      "Question: How do I ask a teacher or school staff for help in a way that is clear and likely to be taken seriously? Give a short script.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "To ask a teacher or school staff for help in a way that is clear and likely to be taken seriously:\n",
      "1. **Identify the Problem**: Clearly state the issue you need help with. For example, \"I'm feeling really upset when [describe the problem].\"\n",
      "2. **Be Specific**: Provide details about the behavior or situation. For instance, \"It happens when [describe the context], and it makes me feel [describe the emotional impact].\"\n",
      "3. **Express Concern**: State your concern directly. For example, \"This is making me feel very uncomfortable.\"\n",
      "4. **Request Help**: Ask for guidance or support. For example, \"Could you please help me figure out how to handle this?\"\n",
      "5. **Offer to Work Together**: Suggest working together to find a solution. For example, \"Would it be possible to talk about this further during [time slot]? I'd appreciate your input.\"\n",
      "Example Script:\n",
      "\"Hi [Teacher's Name],\n",
      "I wanted to talk to you about something that has been bothering me lately. It’s happening when I’m walking home from school, and it makes me feel really upset. Specifically, I see other kids teasing me and calling me names, which makes me feel like I don't belong here anymore.\n",
      "I know you're busy,\n",
      "\n",
      "Top 3 sources used:\n",
      "- [pdf:kidpower_bullying_qa.pdf#p2]\n",
      "- [pdf:bulk_sources/pdfs/cci_self_compassion__Building-Self-Compassion---05---Self-Compassionate-Thinking.pdf#p8]\n",
      "- [pdf:bulk_sources/pdfs/cci_self_compassion__Building-Self-Compassion/Building Self-Compassion - 05 - Self-Compassionate Thinking.pdf#p8]\n",
      "\n",
      "===== Q4 =====\n",
      "Persona: Teen boy, 15, student\n",
      "Question: Give me a 2–3 sentence response to teasing that sets a boundary without escalating, plus what to do right after.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "**Step 1:** When faced with teasing, set a clear boundary by saying, \"I don't like it when you tease me.\" This communicates your feelings clearly without escalating the situation.\n",
      "**Step 2:** After setting the boundary, address the teasing directly. For example, you might say, \"That's not nice. I don't like it when you tease me.\"\n",
      "**Step 3:** If the teasing continues, calmly explain why you find it upsetting. For instance, you could say, \"It makes me feel uncomfortable because it hurts my feelings.\"\n",
      "**Step 4:** Encourage the person to stop the behavior by saying, \"Please don't tease me anymore.\"\n",
      "**Step 5:** If the teasing persists despite your attempts to communicate your boundaries, consider speaking with a trusted adult or a counselor.\n",
      "**Step 6:** Practice assertiveness skills regularly to build confidence and resilience.\n",
      "**Step 7:** Remember, it's okay to seek help if the teasing becomes too much. Don't hesitate to talk to a teacher, principal, or another authority figure.\n",
      "**Step 8:** Stay strong and continue to set boundaries even if others try to push back. Your self-respect and emotional health are important.\n",
      "**Step 9:** Seek support from peers who understand and respect your\n",
      "\n",
      "Top 3 sources used:\n",
      "- [pdf:kidpower_bullying_qa.pdf#p2]\n",
      "- [pdf:kidpower_essp_evaluation_2014.pdf#p6]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself---03---How-to-Think-More-Assertively.pdf#p6]\n",
      "\n",
      "===== Q5 =====\n",
      "Persona: Adult man, 28, workplace employee\n",
      "Question: A coworker repeatedly makes 'jokes' at my expense. How do I set a boundary assertively and document it without escalating?\n",
      "\n",
      "Answer (max 10 lines):\n",
      "To set a boundary assertively and document it without escalating, follow these steps:\n",
      "1. **Identify the behavior**: Recognize that your coworker is making jokes at your expense. Document this observation clearly by noting the specific instances and dates.\n",
      "2. **Choose an appropriate time**: Find a private moment when both of you are relaxed and focused. Avoid confrontational situations during busy work hours.\n",
      "3. **State your boundary clearly**: Use \"I\" statements to express how the behavior affects you. For example, \"I feel uncomfortable when you make jokes about my appearance.\"\n",
      "4. **Be direct and clear**: State your intention to maintain professional boundaries. For instance, \"I need to let you know that I cannot accept jokes about my appearance.\"\n",
      "5. **Document the conversation**: Write down the details of the discussion, including the date, time, location, and your exact words used. Include any agreements made regarding future interactions.\n",
      "6. **Follow up**: After documenting the conversation, check back with your coworker to ensure they understand and respect your boundaries. You might say something like, \"Let's review our agreement to avoid such jokes in the future.\"\n",
      "7. **Seek support**: If the situation persists despite documented boundaries, consider speaking with a supervisor or HR representative who can mediate between\n",
      "\n",
      "Top 3 sources used:\n",
      "- [web:www.nhsinform.scot]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself---06---How-to-Say-No-Assertively.pdf#p6]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself/Assert Yourself - 06 - How to Say No Assertively.pdf#p6]\n",
      "\n",
      "===== Q6 =====\n",
      "Persona: Teen girl, 17, student\n",
      "Question: When I get angry I explode. Give me a CBT-based 3-step routine I can do in under 5 minutes to calm down and respond better.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "**Cognitive Behavioral Therapy-Based Anger Management Routine**\n",
      "1. **Mindfulness Breathing**\n",
      "   - Sit comfortably and close your eyes.\n",
      "   - Breathe in slowly through your nose, filling your lungs completely.\n",
      "   - Hold your breath for a few seconds.\n",
      "   - Exhale slowly through your mouth, allowing your body to release tension.\n",
      "   - Repeat this cycle for several minutes, focusing on your breathing rather than external stimuli.\n",
      "2. **Count to Ten**\n",
      "   - When you feel your anger starting to build up, count to ten silently in your head.\n",
      "   - Focus on each number, counting aloud if necessary.\n",
      "\n",
      "Top 3 sources used:\n",
      "- [web:www.nhsinform.scot]\n",
      "- [web:selfhelp.cntw.nhs.uk]\n",
      "\n",
      "===== Q7 =====\n",
      "Persona: Adult woman, 41, parent\n",
      "Question: My child (10) gets anxious before school. Give 6 practical steps I can coach them to use in the morning.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "**Practical Steps for Your Child to Use Before School**\n",
      "1. **Deep Breathing**: Start with a few deep breaths. Inhale slowly through your nose, hold for a few seconds, and exhale slowly through your mouth. This helps calm the nervous system.\n",
      "2. **Mindfulness Meditation**: Take a moment to focus on your breathing again. Imagine a peaceful place in your mind, like a beach or a forest, and visualize yourself there. This can help distract from anxious thoughts.\n",
      "3. **Positive Affirmations**: Repeat positive affirmations to yourself. For example, \"I am prepared,\" \"I am capable,\" or \"Today will be good.\" These can boost confidence and reduce anxiety.\n",
      "4. **Relaxing Activity**: Engage in a relaxing activity like coloring, drawing, or playing a calming game. This distracts from anxious thoughts and provides a sense of control.\n",
      "5. **Physical Exercise**: Go for a quick walk or stretch. Physical activity releases endorphins, which can improve mood and reduce anxiety.\n",
      "6. **Routine Check-In**: Review the day ahead with your child. Discuss what tasks they need to complete and ensure everything is organized. Knowing what’s expected can alleviate anxiety.\n",
      "These steps should help your child manage their anxiety before school. Remember\n",
      "\n",
      "Top 3 sources used:\n",
      "- [pdf:kidpower_essp_evaluation_2014.pdf#p6]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself---10---Putting-it-All-Together.pdf#p3]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself/Assert Yourself - 10 - Putting it All Together.pdf#p3]\n",
      "\n",
      "===== Q8 =====\n",
      "Persona: Adult man, 40\n",
      "Question: I ruminate for hours after conflicts. Give a CBT-style plan to interrupt rumination and refocus in the moment.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "To interrupt rumination and refocus in the moment after conflicts, follow these CBT-based steps:\n",
      "1. **Recognize Your Emotions**: Identify the specific emotions you're experiencing, such as hurt or anger. Rate their intensity on a scale of 0-100.\n",
      "2. **Physical Response**: Note any physical sensations, such as tense chest or clenched jaw. Reflect on whether these responses align with your emotional state.\n",
      "3. **Behavioral Assessment**: Determine if your behavior was passive, assertive, or aggressive. Consider if you could have been more assertive or empathetic.\n",
      "4. **Thought Analysis**:\n",
      "   - Write down your unhelpful thoughts, such as \"He is looking over here at me and thinks I'm stupid.\"\n",
      "   - Challenge these thoughts by writing a balanced alternative, such as \"He is looking over here but I don't know what he is really thinking.\"\n",
      "5. **Practice Balanced Thinking**:\n",
      "   - Create a thought diary where you record both your unhelpful thoughts and balanced alternatives.\n",
      "   - Practice writing balanced thoughts immediately after encountering unhelpful ones.\n",
      "\n",
      "Top 3 sources used:\n",
      "- [web:selfhelp.cntw.nhs.uk]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself---03---How-to-Think-More-Assertively.pdf#p9]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself/Assert Yourself - 03 - How to Think More Assertively.pdf#p9]\n",
      "\n",
      "===== Q9 =====\n",
      "Persona: Teen boy, 13, student\n",
      "Question: During an argument, things escalate fast. Give me 5 de-escalation techniques I can use safely and respectfully.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "**De-escalation Techniques for Escalating Arguments**\n",
      "1. **Take a Break**: Step away from the argument temporarily. Go to another room or find a quiet place where you can think calmly without distractions.\n",
      "2. **Use \"I\" Statements**: Express your feelings without blaming others. For example, say \"I feel upset when...\" instead of \"You make me upset.\"\n",
      "3. **Stay Calm**: Maintain your composure. Your emotions can escalate quickly during arguments. Deep breathing exercises or mindfulness can help manage stress.\n",
      "4. **Listen Actively**: Show respect by listening carefully to what the other person is saying. Avoid interrupting or dismissing their concerns.\n",
      "5. **Express Empathy**: Acknowledge the other person's feelings. Saying \"I understand how you feel\" shows empathy and helps defuse tension.\n",
      "**Additional Tips**:\n",
      "- **Practice Active Listening**: Make eye contact, nod, and paraphrase what the other person says to show engagement.\n",
      "- **Focus on Solutions**: Instead of dwelling on past grievances, focus on finding solutions together.\n",
      "- **Seek Help**: If the argument becomes too intense, consider seeking support from a trusted adult or counselor.\n",
      "\n",
      "Top 3 sources used:\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself---03---How-to-Think-More-Assertively.pdf#p6]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself/Assert Yourself - 03 - How to Think More Assertively.pdf#p6]\n",
      "- [pdf:bulk_sources/pdfs/cci_assertiveness__Assert-Yourself---03---How-to-Think-More-Assertively.pdf#p6]\n",
      "\n",
      "===== Q10 =====\n",
      "Persona: Adult woman, 52, manager\n",
      "Question: I need a 'win-win' negotiation approach to resolve a repeated conflict with a colleague. Provide a step-by-step structure and a script opener.\n",
      "\n",
      "Answer (max 10 lines):\n",
      "To resolve a repeated conflict with a colleague using a 'win-win' negotiation approach, follow these practical steps:\n",
      "1. **Deep Breathing**: Take a few deep breaths to calm down before initiating the conversation.\n",
      "   - Source: [web:selfhelp.cntw.nhs.uk]\n",
      "2. **Identify the Issue**: Clearly state the issue without blaming or attacking the other person.\n",
      "   - Source: [web:selfhelp.cntw.nhs.uk]\n",
      "3. **Empathize**: Show understanding by acknowledging the other person's perspective.\n",
      "   - Source: [web:selfhelp.cntw.nhs.uk]\n",
      "4. **Propose Solutions**: Offer solutions that benefit both parties.\n",
      "   - Source: [web:selfhelp.cntw.nhs.uk]\n",
      "5. **Negotiate**: Work together to find a mutually acceptable solution.\n",
      "\n",
      "Top 3 sources used:\n",
      "- [web:selfhelp.cntw.nhs.uk]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself---03---How-to-Think-More-Assertively.pdf#p6]\n",
      "- [pdf:bulk_sources/pdfs/cci_interpersonal_clin__Assert-Yourself/Assert Yourself - 03 - How to Think More Assertively.pdf#p6]\n"
     ]
    }
   ],
   "source": [
    "# Define 10 persona-specific questions, run the agent, cap answer to 10 lines, print top 3 sources used\n",
    "\n",
    "import re\n",
    "\n",
    "QUESTIONS = [\n",
    "  (\"Q1\",  \"Adult woman, 34, school counselor\",\n",
    "   \"Define bullying vs a one-time conflict, and list 4 signs that a situation is bullying (not just disagreement).\"),\n",
    "  (\"Q2\",  \"Teen boy, 14, student\",\n",
    "   \"I’m being bullied at school. Give me 5 concrete things I can do this week to reduce risk and get support.\"),\n",
    "  (\"Q3\",  \"Teen girl, 16, student\",\n",
    "   \"How do I ask a teacher or school staff for help in a way that is clear and likely to be taken seriously? Give a short script.\"),\n",
    "  (\"Q4\",  \"Teen boy, 15, student\",\n",
    "   \"Give me a 2–3 sentence response to teasing that sets a boundary without escalating, plus what to do right after.\"),\n",
    "  (\"Q5\",  \"Adult man, 28, workplace employee\",\n",
    "   \"A coworker repeatedly makes 'jokes' at my expense. How do I set a boundary assertively and document it without escalating?\"),\n",
    "  (\"Q6\",  \"Teen girl, 17, student\",\n",
    "   \"When I get angry I explode. Give me a CBT-based 3-step routine I can do in under 5 minutes to calm down and respond better.\"),\n",
    "  (\"Q7\",  \"Adult woman, 41, parent\",\n",
    "   \"My child (10) gets anxious before school. Give 6 practical steps I can coach them to use in the morning.\"),\n",
    "  (\"Q8\",  \"Adult man, 40\",\n",
    "   \"I ruminate for hours after conflicts. Give a CBT-style plan to interrupt rumination and refocus in the moment.\"),\n",
    "  (\"Q9\",  \"Teen boy, 13, student\",\n",
    "   \"During an argument, things escalate fast. Give me 5 de-escalation techniques I can use safely and respectfully.\"),\n",
    "  (\"Q10\", \"Adult woman, 52, manager\",\n",
    "   \"I need a 'win-win' negotiation approach to resolve a repeated conflict with a colleague. Provide a step-by-step structure and a script opener.\")\n",
    "]\n",
    "\n",
    "def _unique_top_sources(hits, n=3):\n",
    "  seen, out = set(), []\n",
    "  for h in hits:\n",
    "    c = format_citation(h[\"meta\"])\n",
    "    if c not in seen:\n",
    "      out.append(c); seen.add(c)\n",
    "    if len(out) >= n:\n",
    "      break\n",
    "  return out\n",
    "\n",
    "def _cap_lines(txt, max_lines=10):\n",
    "  lines = [l.rstrip() for l in (txt or \"\").splitlines() if l.strip() != \"\"]\n",
    "  lines = lines[:max_lines]\n",
    "  return \"\\n\".join(lines).strip()\n",
    "\n",
    "def ask_with_sources(question, k=7, max_new_tokens=260):\n",
    "  q = (question or \"\").strip()\n",
    "  if not q:\n",
    "    return (\"\", [])\n",
    "  hits = retrieve(q, k=k)\n",
    "  if not is_in_scope(q, hits):\n",
    "    return (\"Out of scope for this agent. Ask about bullying, CBT emotion regulation, conflict resolution, or negotiation.\", [])\n",
    "  prompt = build_prompt(\n",
    "    question=q + \"\\n\\nConstraints: Answer in at most 10 lines. Be practical. Keep it appropriate for teens.\",\n",
    "    hits=hits\n",
    "  )\n",
    "  # Generate only the completion (avoid echoing prompt)\n",
    "  messages = [{\"role\":\"system\",\"content\":\"Follow the rules exactly.\"},{\"role\":\"user\",\"content\":prompt}]\n",
    "  try:\n",
    "    inp = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "  except Exception:\n",
    "    inp = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "  inp = inp.to(model.device)\n",
    "  out = model.generate(\n",
    "    inp,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.08\n",
    "  )\n",
    "  gen = out[0][inp.shape[-1]:]\n",
    "  txt = tokenizer.decode(gen, skip_special_tokens=True).strip()\n",
    "  return (_cap_lines(txt, 10), _unique_top_sources(hits, 3))\n",
    "\n",
    "for qid, persona, q in QUESTIONS:\n",
    "  full_q = f\"Persona: {persona}\\nQuestion: {q}\"\n",
    "  ans, srcs = ask_with_sources(full_q, k=7, max_new_tokens=260)\n",
    "  print(f\"\\n===== {qid} =====\")\n",
    "  print(full_q)\n",
    "  print(\"\\nAnswer (max 10 lines):\")\n",
    "  print(ans if ans else \"(no answer)\")\n",
    "  print(\"\\nTop 3 sources used:\")\n",
    "  if srcs:\n",
    "    for s in srcs: print(\"-\", s)\n",
    "  else:\n",
    "    print(\"- (none)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "djzl1IV1BBjW",
    "outputId": "b9cec678-8113-4eaf-d73b-2cd64329b2c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY\n",
      "Exports:\n",
      "- /content/research_agent/exports/showcase_report.md\n",
      "- /content/research_agent/exports/showcase_slides.pptx\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://703883778e1d6a04d9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://703883778e1d6a04d9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip -q install -U gradio sentence-transformers faiss-cpu pymupdf transformers accelerate python-pptx\n",
    "\n",
    "# Import\n",
    "import os, json, time, re, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "import gradio as gr\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "\n",
    "# Define paths\n",
    "WORKDIR = Path(\"/content/research_agent\")\n",
    "RAGDIR  = WORKDIR / \"rag_store\"\n",
    "INDEX_PATH  = RAGDIR / \"faiss.index\"\n",
    "CHUNKS_PATH = RAGDIR / \"chunks.jsonl\"\n",
    "\n",
    "OUTDIR = WORKDIR / \"exports\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load embedder + FAISS + chunks\n",
    "EMBED_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "index = faiss.read_index(str(INDEX_PATH))\n",
    "\n",
    "chunks = []\n",
    "with open(CHUNKS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "      chunks.append(json.loads(line))\n",
    "\n",
    "# Load local instruction model\n",
    "LLM_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE  = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_NAME, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(LLM_NAME, device_map=\"auto\", torch_dtype=DTYPE, low_cpu_mem_usage=True)\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Define citation formatting\n",
    "def format_citation(meta: dict) -> str:\n",
    "  if meta.get(\"source_type\") == \"pdf\":\n",
    "    return f\"[pdf:{meta.get('file','?')}#p{meta.get('page','?')}]\"\n",
    "  if meta.get(\"source_type\") == \"web\":\n",
    "    dom = meta.get(\"domain\",\"web\")\n",
    "    return f\"[web:{dom}]\"\n",
    "  return \"[source]\"\n",
    "\n",
    "# Define retrieval\n",
    "def retrieve(query: str, k: int = 7):\n",
    "  q = (query or \"\").strip()\n",
    "  if not q:\n",
    "    return []\n",
    "  qv = embedder.encode([q], normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "  D, I = index.search(qv, k)\n",
    "  hits = []\n",
    "  for score, idx in zip(D[0].tolist(), I[0].tolist()):\n",
    "    if idx < 0 or idx >= len(chunks):\n",
    "      continue\n",
    "    hits.append({\"score\": float(score), \"meta\": chunks[idx][\"meta\"], \"text\": chunks[idx][\"text\"]})\n",
    "  return hits\n",
    "\n",
    "# Define scope gate\n",
    "SCOPE_KEYWORDS = [\n",
    "  \"bully\", \"bullying\", \"harass\", \"harassment\", \"tease\", \"teasing\", \"intimidat\", \"threat\",\n",
    "  \"anger\", \"anxiety\", \"worry\", \"stress\", \"emotion\", \"regulation\", \"cbt\", \"thought\", \"rumination\",\n",
    "  \"conflict\", \"resolution\", \"negotiat\", \"assert\", \"assertive\", \"boundary\", \"boundaries\", \"de-escalat\"\n",
    "]\n",
    "def is_in_scope(q: str, hits: list) -> bool:\n",
    "  ql = (q or \"\").lower()\n",
    "  kw = any(k in ql for k in SCOPE_KEYWORDS)\n",
    "  best = max([h[\"score\"] for h in hits], default=0.0)\n",
    "  return (kw and best >= 0.18) or (best >= 0.27)\n",
    "\n",
    "# Define sensitive safety gate (keep brief)\n",
    "def is_sensitive_crisis(q: str) -> bool:\n",
    "  ql = (q or \"\").lower()\n",
    "  return any(x in ql for x in [\"suicid\", \"self-harm\", \"self harm\", \"kill myself\", \"end my life\", \"domestic violence\", \"abusive partner\"])\n",
    "\n",
    "# Define prompt builder\n",
    "def build_prompt(question: str, hits: list) -> str:\n",
    "  packed = []\n",
    "  for h in hits:\n",
    "    cite = format_citation(h[\"meta\"])\n",
    "    snippet = textwrap.shorten(h[\"text\"].replace(\"\\n\", \" \"), width=900, placeholder=\"…\")\n",
    "    packed.append(f\"{cite} score={h['score']:.3f}\\n{snippet}\")\n",
    "  sources_block = \"\\n\\n\".join(packed)\n",
    "\n",
    "  return f\"\"\"\n",
    "You are a scope-limited assistant.\n",
    "\n",
    "Allowed topics:\n",
    "- Bullying prevention/response skills (including cyberbullying)\n",
    "- CBT-based emotion regulation (anger/anxiety/stress/worry/rumination)\n",
    "- Conflict resolution, negotiation, assertiveness, boundaries, de-escalation\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY using the provided sources\n",
    "- If sources are insufficient, say you do not have enough information and ask for a source to add\n",
    "- If question is out of scope, refuse politely and say it is out of scope\n",
    "- Keep advice practical, non-graphic, and appropriate for teens\n",
    "- Write at most 10 lines\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Sources:\n",
    "{sources_block}\n",
    "\n",
    "Write the answer as bullets or numbered steps, with inline citations after key claims using the provided [pdf:...#p..] or [web:domain] tags.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Define generation (pass attention_mask to avoid warning)\n",
    "def generate_from_prompt(prompt: str, max_new_tokens: int = 260) -> str:\n",
    "  messages = [{\"role\":\"system\",\"content\":\"Follow the rules exactly.\"},{\"role\":\"user\",\"content\":prompt}]\n",
    "  try:\n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "  except Exception:\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "  input_ids = input_ids.to(model.device)\n",
    "  attention_mask = torch.ones_like(input_ids)\n",
    "  pad_id = tokenizer.eos_token_id\n",
    "\n",
    "  out = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.08,\n",
    "    pad_token_id=pad_id\n",
    "  )\n",
    "  gen = out[0][input_ids.shape[-1]:]\n",
    "  txt = tokenizer.decode(gen, skip_special_tokens=True).strip()\n",
    "  return txt\n",
    "\n",
    "# Define helpers\n",
    "def top_sources(hits, n=3):\n",
    "  seen, out = set(), []\n",
    "  for h in hits:\n",
    "    c = format_citation(h[\"meta\"])\n",
    "    if c not in seen:\n",
    "      out.append(c); seen.add(c)\n",
    "    if len(out) >= n:\n",
    "      break\n",
    "  return out\n",
    "\n",
    "def cap_lines(txt, max_lines=10):\n",
    "  lines = [l.strip() for l in (txt or \"\").splitlines() if l.strip()]\n",
    "  return \"\\n\".join(lines[:max_lines])\n",
    "\n",
    "# Define ask()\n",
    "def ask(question: str, k: int = 7):\n",
    "  q = (question or \"\").strip()\n",
    "  if not q:\n",
    "    return (\"Ask a question.\", \"\")\n",
    "  if is_sensitive_crisis(q):\n",
    "    return (\"If someone might be in immediate danger, contact local emergency services or a trusted adult/professional now. \"\n",
    "            \"I can help with general coping and communication steps within this agent’s scope.\", \"\")\n",
    "\n",
    "  hits = retrieve(q, k=k)\n",
    "  if not is_in_scope(q, hits):\n",
    "    return (\"Out of scope for this agent. Ask about bullying, CBT emotion regulation, conflict resolution, negotiation, assertiveness, or boundaries.\", \"\")\n",
    "\n",
    "  prompt = build_prompt(q, hits)\n",
    "  ans = cap_lines(generate_from_prompt(prompt), 10)\n",
    "  srcs = \"\\n\".join(top_sources(hits, 3))\n",
    "  return (ans, srcs)\n",
    "\n",
    "# Define 10 showcase questions\n",
    "SHOWCASE_QS = [\n",
    "  (\"Q1\",  \"Persona: Adult woman, 34, school counselor\\nQuestion: Define bullying vs a one-time conflict, and list 4 signs that a situation is bullying (not just disagreement).\"),\n",
    "  (\"Q2\",  \"Persona: Teen boy, 14, student\\nQuestion: I’m being bullied at school. Give 5 concrete things I can do this week to reduce risk and get support.\"),\n",
    "  (\"Q3\",  \"Persona: Teen girl, 16, student\\nQuestion: How do I ask a teacher or school staff for help in a way that is clear and likely to be taken seriously? Give a short script.\"),\n",
    "  (\"Q4\",  \"Persona: Teen boy, 15, student\\nQuestion: Give me a 2–3 sentence response to teasing that sets a boundary without escalating, plus what to do right after.\"),\n",
    "  (\"Q5\",  \"Persona: Adult man, 28, workplace employee\\nQuestion: A coworker repeatedly makes 'jokes' at my expense. How do I set a boundary assertively and document it without escalating?\"),\n",
    "  (\"Q6\",  \"Persona: Teen girl, 17, student\\nQuestion: When I get angry I explode. Give me a CBT-based 3-step routine I can do in under 5 minutes to calm down and respond better.\"),\n",
    "  (\"Q7\",  \"Persona: Adult woman, 41, parent\\nQuestion: My child (10) gets anxious before school. Give 6 practical steps I can coach them to use in the morning.\"),\n",
    "  (\"Q8\",  \"Persona: Adult man, 40\\nQuestion: I ruminate for hours after conflicts. Give a CBT-style plan to interrupt rumination and refocus in the moment.\"),\n",
    "  (\"Q9\",  \"Persona: Teen boy, 13, student\\nQuestion: During an argument, things escalate fast. Give 5 de-escalation techniques I can use safely and respectfully.\"),\n",
    "  (\"Q10\", \"Persona: Adult woman, 52, manager\\nQuestion: I need a 'win-win' negotiation approach to resolve a repeated conflict with a colleague. Provide a step-by-step structure and a script opener.\"),\n",
    "]\n",
    "\n",
    "# Define export report\n",
    "def export_showcase():\n",
    "  md_path = OUTDIR / \"showcase_report.md\"\n",
    "  pptx_path = OUTDIR / \"showcase_slides.pptx\"\n",
    "\n",
    "  lines = []\n",
    "  lines.append(\"# Bullying + CBT + Conflict Skills Agent — Showcase Pack\")\n",
    "  lines.append(f\"- Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "  lines.append(f\"- Model: {LLM_NAME}\")\n",
    "  lines.append(\"\")\n",
    "\n",
    "  slides = Presentation()\n",
    "  title_slide = slides.slides.add_slide(slides.slide_layouts[0])\n",
    "  title_slide.shapes.title.text = \"Bullying + CBT + Conflict Skills Agent\"\n",
    "  title_slide.placeholders[1].text = \"Showcase Pack (10 Q&A)\\nCited answers from indexed sources\"\n",
    "\n",
    "  for qid, q in SHOWCASE_QS:\n",
    "    ans, srcs = ask(q, k=7)\n",
    "    lines.append(f\"## {qid}\")\n",
    "    lines.append(q)\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"**Answer (≤10 lines)**\")\n",
    "    lines.append(ans)\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"**Top 3 sources**\")\n",
    "    lines.append(srcs if srcs else \"(none)\")\n",
    "    lines.append(\"\\n---\\n\")\n",
    "\n",
    "    slide = slides.slides.add_slide(slides.slide_layouts[1])\n",
    "    slide.shapes.title.text = qid\n",
    "    body = slide.shapes.placeholders[1].text_frame\n",
    "    body.clear()\n",
    "    for bullet in (ans.splitlines()[:10] if ans else [\"(no answer)\"]):\n",
    "      p = body.add_paragraph() if body.text else body.paragraphs[0]\n",
    "      p.text = bullet\n",
    "      p.level = 0\n",
    "      p.font.size = Pt(16)\n",
    "    if srcs:\n",
    "      p = body.add_paragraph()\n",
    "      p.text = \"Sources: \" + \", \".join(srcs.splitlines())\n",
    "      p.level = 0\n",
    "      p.font.size = Pt(12)\n",
    "\n",
    "  md_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "  slides.save(str(pptx_path))\n",
    "  return (str(md_path), str(pptx_path))\n",
    "\n",
    "md_file, pptx_file = export_showcase()\n",
    "print(\"READY\")\n",
    "print(\"Exports:\")\n",
    "print(\"-\", md_file)\n",
    "print(\"-\", pptx_file)\n",
    "\n",
    "# Launch UI\n",
    "with gr.Blocks() as app:\n",
    "  gr.Markdown(\"## Bullying + CBT + Conflict Skills Agent\\nAsk a question (in scope). The answer is capped to 10 lines and shows top sources.\")\n",
    "  q_in = gr.Textbox(lines=4, label=\"Question (include persona: age + role)\")\n",
    "  k_in = gr.Slider(3, 12, value=7, step=1, label=\"Top-K retrieval\")\n",
    "  ans_out = gr.Textbox(lines=10, label=\"Answer (≤10 lines)\")\n",
    "  src_out = gr.Textbox(lines=4, label=\"Top 3 sources\")\n",
    "  run_btn = gr.Button(\"Ask\")\n",
    "  run_btn.click(fn=ask, inputs=[q_in, k_in], outputs=[ans_out, src_out])\n",
    "\n",
    "  gr.Markdown(\"### Exports\")\n",
    "  gr.Markdown(f\"- Markdown report: `{md_file}`\\n- Slides: `{pptx_file}`\")\n",
    "\n",
    "app.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}